tritonserver \
	--model-repository=s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd \
	--allow-metrics=1 \
	--metrics-config summary_latencies=true \
	--log-verbose=1
I0807 13:44:30.635890 28 cache_manager.cc:480] "Create CacheManager with cache_dir: '/opt/tritonserver/caches'"
I0807 13:44:31.074327 28 pinned_memory_manager.cc:275] "Pinned memory pool is created at '0x7f73ee000000' with size 268435456"
I0807 13:44:31.076395 28 cuda_memory_manager.cc:107] "CUDA memory pool is created on device 0 with size 67108864"
I0807 13:44:31.079751 28 api.cc:304] "TRITON_CLOUD_CREDENTIAL_PATH environment variable is not set, reading from environment variables"
I0807 13:44:31.079782 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd"
I0807 13:44:39.425659 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd"
I0807 13:44:39.560308 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-onnx"
I0807 13:44:39.572115 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-onnx"
I0807 13:44:39.583559 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-onnx"
I0807 13:44:39.592892 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-onnx/1"
I0807 13:44:39.605084 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-onnx/1"
I0807 13:44:39.617341 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-onnx/1"
I0807 13:44:39.668261 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-onnx/1/config.json"
I0807 13:44:39.720015 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-onnx/1/config.json"
I0807 13:44:39.775181 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-onnx/1/model.onnx"
I0807 13:44:39.828012 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-onnx/1/model.onnx"
I0807 13:44:39.883474 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-onnx/1/model.onnx_data"
I0807 13:44:39.936034 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-onnx/1/model.onnx_data"
I0807 13:44:39.991372 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-onnx/config.pbtxt"
I0807 13:44:40.044063 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-onnx/config.pbtxt"
I0807 13:44:40.098917 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-onnx/warmup"
I0807 13:44:40.110997 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-onnx/warmup"
I0807 13:44:40.127227 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-onnx/warmup"
I0807 13:44:40.176520 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-onnx/warmup/1"
I0807 13:44:40.232309 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-onnx/warmup/1"
I0807 13:44:40.284272 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-onnx/warmup/1"
I0807 13:44:40.336259 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-onnx/warmup/1/raw_attention_mask"
I0807 13:44:40.388034 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-onnx/warmup/1/raw_attention_mask"
I0807 13:44:40.463052 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-onnx/warmup/1/raw_input_ids"
I0807 13:44:40.516023 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-onnx/warmup/1/raw_input_ids"
I0807 13:44:40.571091 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-onnx/warmup/256"
I0807 13:44:40.624282 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-onnx/warmup/256"
I0807 13:44:40.680252 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-onnx/warmup/256"
I0807 13:44:40.732375 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-onnx/warmup/256/raw_attention_mask"
I0807 13:44:40.784037 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-onnx/warmup/256/raw_attention_mask"
I0807 13:44:40.842731 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-onnx/warmup/256/raw_input_ids"
I0807 13:44:40.892009 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-onnx/warmup/256/raw_input_ids"
I0807 13:44:40.947096 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-onnx/config.pbtxt"
I0807 13:44:41.002641 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-onnx/config.pbtxt"
I0807 13:44:41.064315 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-onnx"
I0807 13:44:41.236517 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-onnx/1"
I0807 13:44:41.245593 28 model_config_utils.cc:681] "Server side auto-completed config: "
name: "multilingual-e5-large-onnx"
platform: "onnxruntime_onnx"
version_policy {
  specific {
    versions: 1
  }
}
max_batch_size: 256
input {
  name: "attention_mask"
  data_type: TYPE_INT64
  dims: -1
}
input {
  name: "input_ids"
  data_type: TYPE_INT64
  dims: -1
}
output {
  name: "sentence_embedding"
  data_type: TYPE_FP32
  dims: 1024
}
instance_group {
  name: "onnx_gpu_group"
  count: 1
  gpus: 0
  kind: KIND_GPU
}
default_model_filename: "model.onnx"
dynamic_batching {
  preferred_batch_size: 64
  preferred_batch_size: 128
  preferred_batch_size: 256
  max_queue_delay_microseconds: 10000
}
optimization {
  execution_accelerators {
    gpu_execution_accelerator {
      name: "tensorrt"
      parameters {
        key: "max_workspace_size_bytes"
        value: "8589934592"
      }
      parameters {
        key: "precision_mode"
        value: "FP16"
      }
    }
  }
}
model_warmup {
  name: "onnx_ort_warmup_min"
  batch_size: 1
  inputs {
    key: "attention_mask"
    value {
      data_type: TYPE_INT64
      dims: 4
      input_data_file: "1/raw_attention_mask"
    }
  }
  inputs {
    key: "input_ids"
    value {
      data_type: TYPE_INT64
      dims: 4
      input_data_file: "1/raw_input_ids"
    }
  }
}
model_warmup {
  name: "onnx_ort_warmup_max"
  batch_size: 256
  inputs {
    key: "attention_mask"
    value {
      data_type: TYPE_INT64
      dims: 512
      input_data_file: "256/raw_attention_mask"
    }
  }
  inputs {
    key: "input_ids"
    value {
      data_type: TYPE_INT64
      dims: 512
      input_data_file: "256/raw_input_ids"
    }
  }
}
backend: "onnxruntime"

I0807 13:44:41.245790 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-postprocessing"
I0807 13:44:41.257003 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-postprocessing"
I0807 13:44:41.308408 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-postprocessing"
I0807 13:44:41.316760 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-postprocessing/1"
I0807 13:44:41.328310 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-postprocessing/1"
I0807 13:44:41.339545 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-postprocessing/1"
I0807 13:44:41.349510 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-postprocessing/1/__pycache__"
I0807 13:44:41.404656 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-postprocessing/1/__pycache__"
I0807 13:44:41.460013 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-postprocessing/1/__pycache__"
I0807 13:44:41.512266 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-postprocessing/1/__pycache__/model.cpython-310.pyc"
I0807 13:44:41.568066 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-postprocessing/1/__pycache__/model.cpython-310.pyc"
I0807 13:44:41.623150 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-postprocessing/1/model.py"
I0807 13:44:41.680015 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-postprocessing/1/model.py"
I0807 13:44:41.735215 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-postprocessing/config.pbtxt"
I0807 13:44:41.796050 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-postprocessing/config.pbtxt"
I0807 13:44:41.851061 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-postprocessing/config.pbtxt"
I0807 13:44:41.910654 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-postprocessing/config.pbtxt"
I0807 13:44:42.016014 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-postprocessing"
I0807 13:44:42.128091 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-postprocessing/1"
I0807 13:44:42.137110 28 model_config_utils.cc:681] "Server side auto-completed config: "
name: "multilingual-e5-large-postprocessing"
max_batch_size: 256
input {
  name: "input_vector"
  data_type: TYPE_FP32
  dims: 1024
}
output {
  name: "output_vector"
  data_type: TYPE_FP32
  dims: 1024
}
instance_group {
  count: 10
  kind: KIND_CPU
}
default_model_filename: "model.py"
backend: "python"

I0807 13:44:42.137220 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-preprocessing"
I0807 13:44:42.192590 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-preprocessing"
I0807 13:44:42.205363 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-preprocessing"
I0807 13:44:42.213091 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-preprocessing/1"
I0807 13:44:42.268375 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-preprocessing/1"
I0807 13:44:42.280064 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-preprocessing/1"
I0807 13:44:42.288700 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-preprocessing/1/__pycache__"
I0807 13:44:42.348267 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-preprocessing/1/__pycache__"
I0807 13:44:42.400249 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-preprocessing/1/__pycache__"
I0807 13:44:42.452256 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-preprocessing/1/__pycache__/model.cpython-310.pyc"
I0807 13:44:42.504051 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-preprocessing/1/__pycache__/model.cpython-310.pyc"
I0807 13:44:42.559500 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-preprocessing/1/model.py"
I0807 13:44:42.612111 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-preprocessing/1/model.py"
I0807 13:44:42.667682 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-preprocessing/config.pbtxt"
I0807 13:44:42.724106 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-preprocessing/config.pbtxt"
I0807 13:44:42.779183 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-preprocessing/config.pbtxt"
I0807 13:44:42.834814 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-preprocessing/config.pbtxt"
I0807 13:44:42.944019 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-preprocessing"
I0807 13:44:43.012068 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-preprocessing/1"
I0807 13:44:43.068284 28 model_config_utils.cc:681] "Server side auto-completed config: "
name: "multilingual-e5-large-preprocessing"
max_batch_size: 256
input {
  name: "text"
  data_type: TYPE_STRING
  dims: 1
}
output {
  name: "output_attention_mask"
  data_type: TYPE_INT64
  dims: 512
}
output {
  name: "output_input_ids"
  data_type: TYPE_INT64
  dims: 512
}
instance_group {
  count: 10
  kind: KIND_CPU
}
default_model_filename: "model.py"
backend: "python"

I0807 13:44:43.068391 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/wb_embedder_v0"
I0807 13:44:43.124237 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/wb_embedder_v0"
I0807 13:44:43.184322 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/wb_embedder_v0"
I0807 13:44:43.236369 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/wb_embedder_v0/1"
I0807 13:44:43.288113 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/wb_embedder_v0/1"
I0807 13:44:43.340121 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/wb_embedder_v0/1"
I0807 13:44:43.388113 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/wb_embedder_v0/config.pbtxt"
I0807 13:44:43.444047 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/wb_embedder_v0/config.pbtxt"
I0807 13:44:43.499552 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/wb_embedder_v0/config.pbtxt"
I0807 13:44:43.555370 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/wb_embedder_v0/config.pbtxt"
I0807 13:44:43.660375 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/wb_embedder_v0"
I0807 13:44:43.812080 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/wb_embedder_v0/1"
I0807 13:44:43.860286 28 model_config_utils.cc:681] "Server side auto-completed config: "
name: "wb_embedder_v0"
platform: "ensemble"
max_batch_size: 256
input {
  name: "INPUT_TEXT"
  data_type: TYPE_STRING
  dims: 1
}
output {
  name: "OUTPUT"
  data_type: TYPE_FP32
  dims: 1024
}
ensemble_scheduling {
  step {
    model_name: "multilingual-e5-large-preprocessing"
    model_version: -1
    input_map {
      key: "text"
      value: "INPUT_TEXT"
    }
    output_map {
      key: "output_attention_mask"
      value: "OUTPUT_ATTENTION_MASK"
    }
    output_map {
      key: "output_input_ids"
      value: "OUTPUT_INPUT_IDS"
    }
  }
  step {
    model_name: "multilingual-e5-large-onnx"
    model_version: 1
    input_map {
      key: "attention_mask"
      value: "OUTPUT_ATTENTION_MASK"
    }
    input_map {
      key: "input_ids"
      value: "OUTPUT_INPUT_IDS"
    }
    output_map {
      key: "sentence_embedding"
      value: "OUTPUT_EMBEDDING"
    }
  }
  step {
    model_name: "multilingual-e5-large-postprocessing"
    model_version: -1
    input_map {
      key: "input_vector"
      value: "OUTPUT_EMBEDDING"
    }
    output_map {
      key: "output_vector"
      value: "OUTPUT"
    }
  }
}

I0807 13:44:43.860621 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-preprocessing"
I0807 13:44:44.016117 28 model_lifecycle.cc:472] "loading: multilingual-e5-large-preprocessing:1"
I0807 13:44:44.016179 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-postprocessing"
I0807 13:44:44.016262 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-preprocessing"
I0807 13:44:44.092096 28 model_lifecycle.cc:472] "loading: multilingual-e5-large-postprocessing:1"
I0807 13:44:44.092153 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-onnx"
I0807 13:44:44.092240 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-postprocessing"
I0807 13:44:44.224117 28 model_lifecycle.cc:472] "loading: multilingual-e5-large-onnx:1"
I0807 13:44:44.224231 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-onnx"
I0807 13:44:44.603499 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-preprocessing/1/libtriton_python.so"
I0807 13:44:44.658594 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-preprocessing/libtriton_python.so"
I0807 13:44:44.663655 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-postprocessing/1/libtriton_python.so"
I0807 13:44:44.714927 28 backend_model.cc:503] "Adding default backend config setting: default-max-batch-size,4"
I0807 13:44:44.714992 28 shared_library.cc:112] "OpenLibraryHandle: /opt/tritonserver/backends/python/libtriton_python.so"
I0807 13:44:44.718157 28 python_be.cc:2099] "'python' TRITONBACKEND API version: 1.19"
I0807 13:44:44.718203 28 python_be.cc:2121] "backend configuration:\n{\"cmdline\":{\"auto-complete-config\":\"true\",\"backend-directory\":\"/opt/tritonserver/backends\",\"min-compute-capability\":\"6.000000\",\"default-max-batch-size\":\"4\"}}"
I0807 13:44:44.718280 28 python_be.cc:2259] "Shared memory configuration is shm-default-byte-size=1048576,shm-growth-byte-size=1048576,stub-timeout-seconds=30"
I0807 13:44:44.718515 28 python_be.cc:2582] "TRITONBACKEND_GetBackendAttribute: setting attributes"
I0807 13:44:44.718679 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-postprocessing/libtriton_python.so"
I0807 13:44:44.720976 28 python_be.cc:2360] "TRITONBACKEND_ModelInitialize: multilingual-e5-large-preprocessing (version 1)"
I0807 13:44:44.722198 28 model_config_utils.cc:1902] "ModelConfig 64-bit fields:"
I0807 13:44:44.722228 28 model_config_utils.cc:1904] "\tModelConfig::dynamic_batching::default_priority_level"
I0807 13:44:44.722248 28 model_config_utils.cc:1904] "\tModelConfig::dynamic_batching::default_queue_policy::default_timeout_microseconds"
I0807 13:44:44.722267 28 model_config_utils.cc:1904] "\tModelConfig::dynamic_batching::max_queue_delay_microseconds"
I0807 13:44:44.722286 28 model_config_utils.cc:1904] "\tModelConfig::dynamic_batching::priority_levels"
I0807 13:44:44.722304 28 model_config_utils.cc:1904] "\tModelConfig::dynamic_batching::priority_queue_policy::key"
I0807 13:44:44.722323 28 model_config_utils.cc:1904] "\tModelConfig::dynamic_batching::priority_queue_policy::value::default_timeout_microseconds"
I0807 13:44:44.722342 28 model_config_utils.cc:1904] "\tModelConfig::ensemble_scheduling::step::model_version"
I0807 13:44:44.722360 28 model_config_utils.cc:1904] "\tModelConfig::input::dims"
I0807 13:44:44.722381 28 model_config_utils.cc:1904] "\tModelConfig::input::reshape::shape"
I0807 13:44:44.722399 28 model_config_utils.cc:1904] "\tModelConfig::instance_group::secondary_devices::device_id"
I0807 13:44:44.722418 28 model_config_utils.cc:1904] "\tModelConfig::model_warmup::inputs::value::dims"
I0807 13:44:44.722436 28 model_config_utils.cc:1904] "\tModelConfig::optimization::cuda::graph_spec::graph_lower_bound::input::value::dim"
I0807 13:44:44.722455 28 model_config_utils.cc:1904] "\tModelConfig::optimization::cuda::graph_spec::input::value::dim"
I0807 13:44:44.722473 28 model_config_utils.cc:1904] "\tModelConfig::output::dims"
I0807 13:44:44.722491 28 model_config_utils.cc:1904] "\tModelConfig::output::reshape::shape"
I0807 13:44:44.722509 28 model_config_utils.cc:1904] "\tModelConfig::sequence_batching::direct::max_queue_delay_microseconds"
I0807 13:44:44.722528 28 model_config_utils.cc:1904] "\tModelConfig::sequence_batching::max_sequence_idle_microseconds"
I0807 13:44:44.722546 28 model_config_utils.cc:1904] "\tModelConfig::sequence_batching::oldest::max_queue_delay_microseconds"
I0807 13:44:44.722564 28 model_config_utils.cc:1904] "\tModelConfig::sequence_batching::state::dims"
I0807 13:44:44.722582 28 model_config_utils.cc:1904] "\tModelConfig::sequence_batching::state::initial_state::dims"
I0807 13:44:44.722602 28 model_config_utils.cc:1904] "\tModelConfig::version_policy::specific::versions"
I0807 13:44:44.724108 28 stub_launcher.cc:385] "Starting Python backend stub:  exec /opt/tritonserver/backends/python/triton_python_backend_stub /tmp/folderW5fXFM/1/model.py triton_python_backend_shm_region_4465099a-ada1-4f7a-9f1d-c12729bc13e0 1048576 1048576 28 /opt/tritonserver/backends/python 336 multilingual-e5-large-preprocessing DEFAULT"
I0807 13:44:44.775451 28 backend_model.cc:503] "Adding default backend config setting: default-max-batch-size,4"
I0807 13:44:44.778508 28 python_be.cc:2360] "TRITONBACKEND_ModelInitialize: multilingual-e5-large-postprocessing (version 1)"
I0807 13:44:44.781674 28 stub_launcher.cc:385] "Starting Python backend stub:  exec /opt/tritonserver/backends/python/triton_python_backend_stub /tmp/folderCCnL9t/1/model.py triton_python_backend_shm_region_d7d5c543-76cc-4d98-85cd-39005f2360db 1048576 1048576 28 /opt/tritonserver/backends/python 336 multilingual-e5-large-postprocessing DEFAULT"
I0807 13:44:46.432571 28 python_be.cc:2055] "model configuration:\n{\n    \"name\": \"multilingual-e5-large-postprocessing\",\n    \"platform\": \"\",\n    \"backend\": \"python\",\n    \"runtime\": \"\",\n    \"version_policy\": {\n        \"latest\": {\n            \"num_versions\": 1\n        }\n    },\n    \"max_batch_size\": 256,\n    \"input\": [\n        {\n            \"name\": \"input_vector\",\n            \"data_type\": \"TYPE_FP32\",\n            \"format\": \"FORMAT_NONE\",\n            \"dims\": [\n                1024\n            ],\n            \"is_shape_tensor\": false,\n            \"allow_ragged_batch\": false,\n            \"optional\": false\n        }\n    ],\n    \"output\": [\n        {\n            \"name\": \"output_vector\",\n            \"data_type\": \"TYPE_FP32\",\n            \"dims\": [\n                1024\n            ],\n            \"label_filename\": \"\",\n            \"is_shape_tensor\": false\n        }\n    ],\n    \"batch_input\": [],\n    \"batch_output\": [],\n    \"optimization\": {\n        \"priority\": \"PRIORITY_DEFAULT\",\n        \"input_pinned_memory\": {\n            \"enable\": true\n        },\n        \"output_pinned_memory\": {\n            \"enable\": true\n        },\n        \"gather_kernel_buffer_threshold\": 0,\n        \"eager_batching\": false\n    },\n    \"instance_group\": [\n        {\n            \"name\": \"multilingual-e5-large-postprocessing_0\",\n            \"kind\": \"KIND_CPU\",\n            \"count\": 10,\n            \"gpus\": [],\n            \"secondary_devices\": [],\n            \"profile\": [],\n            \"passive\": false,\n            \"host_policy\": \"\"\n        }\n    ],\n    \"default_model_filename\": \"model.py\",\n    \"cc_model_filenames\": {},\n    \"metric_tags\": {},\n    \"parameters\": {},\n    \"model_warmup\": []\n}"
I0807 13:44:46.432799 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-postprocessing/1/batchstrategy.so"
I0807 13:44:46.488091 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-postprocessing/batchstrategy.so"
I0807 13:44:46.542293 28 python_be.cc:2404] "TRITONBACKEND_ModelInstanceInitialize: multilingual-e5-large-postprocessing_0_0 (CPU device 0)"
I0807 13:44:46.542346 28 backend_model_instance.cc:69] "Creating instance multilingual-e5-large-postprocessing_0_0 on CPU using artifact 'model.py'"
I0807 13:44:46.542599 28 python_be.cc:2404] "TRITONBACKEND_ModelInstanceInitialize: multilingual-e5-large-postprocessing_0_1 (CPU device 0)"
I0807 13:44:46.542646 28 python_be.cc:2404] "TRITONBACKEND_ModelInstanceInitialize: multilingual-e5-large-postprocessing_0_2 (CPU device 0)"
I0807 13:44:46.542664 28 backend_model_instance.cc:69] "Creating instance multilingual-e5-large-postprocessing_0_1 on CPU using artifact 'model.py'"
I0807 13:44:46.542732 28 python_be.cc:2404] "TRITONBACKEND_ModelInstanceInitialize: multilingual-e5-large-postprocessing_0_3 (CPU device 0)"
I0807 13:44:46.542764 28 backend_model_instance.cc:69] "Creating instance multilingual-e5-large-postprocessing_0_3 on CPU using artifact 'model.py'"
I0807 13:44:46.542714 28 backend_model_instance.cc:69] "Creating instance multilingual-e5-large-postprocessing_0_2 on CPU using artifact 'model.py'"
I0807 13:44:46.542929 28 python_be.cc:2404] "TRITONBACKEND_ModelInstanceInitialize: multilingual-e5-large-postprocessing_0_5 (CPU device 0)"
I0807 13:44:46.542942 28 python_be.cc:2404] "TRITONBACKEND_ModelInstanceInitialize: multilingual-e5-large-postprocessing_0_4 (CPU device 0)"
I0807 13:44:46.542958 28 backend_model_instance.cc:69] "Creating instance multilingual-e5-large-postprocessing_0_5 on CPU using artifact 'model.py'"
I0807 13:44:46.543001 28 backend_model_instance.cc:69] "Creating instance multilingual-e5-large-postprocessing_0_4 on CPU using artifact 'model.py'"
I0807 13:44:46.544021 28 python_be.cc:2404] "TRITONBACKEND_ModelInstanceInitialize: multilingual-e5-large-postprocessing_0_6 (CPU device 0)"
I0807 13:44:46.544050 28 backend_model_instance.cc:69] "Creating instance multilingual-e5-large-postprocessing_0_6 on CPU using artifact 'model.py'"
I0807 13:44:46.544114 28 python_be.cc:2404] "TRITONBACKEND_ModelInstanceInitialize: multilingual-e5-large-postprocessing_0_7 (CPU device 0)"
I0807 13:44:46.544143 28 backend_model_instance.cc:69] "Creating instance multilingual-e5-large-postprocessing_0_7 on CPU using artifact 'model.py'"
I0807 13:44:46.544426 28 python_be.cc:2404] "TRITONBACKEND_ModelInstanceInitialize: multilingual-e5-large-postprocessing_0_8 (CPU device 0)"
I0807 13:44:46.544455 28 backend_model_instance.cc:69] "Creating instance multilingual-e5-large-postprocessing_0_8 on CPU using artifact 'model.py'"
I0807 13:44:46.544552 28 stub_launcher.cc:385] "Starting Python backend stub:  exec /opt/tritonserver/backends/python/triton_python_backend_stub /tmp/folderCCnL9t/1/model.py triton_python_backend_shm_region_0c991ec9-cbc1-4f2a-8b7a-29ef1446c1bc 1048576 1048576 28 /opt/tritonserver/backends/python 336 multilingual-e5-large-postprocessing_0_1 DEFAULT"
I0807 13:44:46.544734 28 python_be.cc:2404] "TRITONBACKEND_ModelInstanceInitialize: multilingual-e5-large-postprocessing_0_9 (CPU device 0)"
I0807 13:44:46.544774 28 stub_launcher.cc:385] "Starting Python backend stub:  exec /opt/tritonserver/backends/python/triton_python_backend_stub /tmp/folderCCnL9t/1/model.py triton_python_backend_shm_region_09962c5b-4582-44f9-a009-88882e7bc786 1048576 1048576 28 /opt/tritonserver/backends/python 336 multilingual-e5-large-postprocessing_0_2 DEFAULT"
I0807 13:44:46.544779 28 stub_launcher.cc:385] "Starting Python backend stub:  exec /opt/tritonserver/backends/python/triton_python_backend_stub /tmp/folderCCnL9t/1/model.py triton_python_backend_shm_region_b11237dc-29ff-4e23-af77-04985a3b1835 1048576 1048576 28 /opt/tritonserver/backends/python 336 multilingual-e5-large-postprocessing_0_3 DEFAULT"
I0807 13:44:46.544814 28 stub_launcher.cc:385] "Starting Python backend stub:  exec /opt/tritonserver/backends/python/triton_python_backend_stub /tmp/folderCCnL9t/1/model.py triton_python_backend_shm_region_d825aee4-2344-4b98-8f24-3222a27211e7 1048576 1048576 28 /opt/tritonserver/backends/python 336 multilingual-e5-large-postprocessing_0_0 DEFAULT"
I0807 13:44:46.544788 28 backend_model_instance.cc:69] "Creating instance multilingual-e5-large-postprocessing_0_9 on CPU using artifact 'model.py'"
I0807 13:44:46.545073 28 stub_launcher.cc:385] "Starting Python backend stub:  exec /opt/tritonserver/backends/python/triton_python_backend_stub /tmp/folderCCnL9t/1/model.py triton_python_backend_shm_region_da4680c7-9638-412b-b569-5eab61056bf4 1048576 1048576 28 /opt/tritonserver/backends/python 336 multilingual-e5-large-postprocessing_0_5 DEFAULT"
I0807 13:44:46.545864 28 stub_launcher.cc:385] "Starting Python backend stub:  exec /opt/tritonserver/backends/python/triton_python_backend_stub /tmp/folderCCnL9t/1/model.py triton_python_backend_shm_region_ba7e42ff-6d43-4b9e-a4cf-4390fda7b120 1048576 1048576 28 /opt/tritonserver/backends/python 336 multilingual-e5-large-postprocessing_0_4 DEFAULT"
I0807 13:44:46.546260 28 stub_launcher.cc:385] "Starting Python backend stub:  exec /opt/tritonserver/backends/python/triton_python_backend_stub /tmp/folderCCnL9t/1/model.py triton_python_backend_shm_region_421d8fc4-2de2-4e50-8ec3-db2cddac33c5 1048576 1048576 28 /opt/tritonserver/backends/python 336 multilingual-e5-large-postprocessing_0_6 DEFAULT"
I0807 13:44:46.546323 28 stub_launcher.cc:385] "Starting Python backend stub:  exec /opt/tritonserver/backends/python/triton_python_backend_stub /tmp/folderCCnL9t/1/model.py triton_python_backend_shm_region_78f33da5-26fc-41ab-b5c0-e932d733e701 1048576 1048576 28 /opt/tritonserver/backends/python 336 multilingual-e5-large-postprocessing_0_7 DEFAULT"
I0807 13:44:46.547815 28 stub_launcher.cc:385] "Starting Python backend stub:  exec /opt/tritonserver/backends/python/triton_python_backend_stub /tmp/folderCCnL9t/1/model.py triton_python_backend_shm_region_daf6ebbd-b2bf-4b04-bfad-84b368c1dde0 1048576 1048576 28 /opt/tritonserver/backends/python 336 multilingual-e5-large-postprocessing_0_8 DEFAULT"
I0807 13:44:46.547853 28 stub_launcher.cc:385] "Starting Python backend stub:  exec /opt/tritonserver/backends/python/triton_python_backend_stub /tmp/folderCCnL9t/1/model.py triton_python_backend_shm_region_cfe70e4c-7de5-4513-a4b1-14a12641aa9a 1048576 1048576 28 /opt/tritonserver/backends/python 336 multilingual-e5-large-postprocessing_0_9 DEFAULT"
I0807 13:44:47.590926 28 model.py:32] "Successfull postprocessor init!"
I0807 13:44:47.600625 28 python_be.cc:2425] "TRITONBACKEND_ModelInstanceInitialize: instance initialization successful multilingual-e5-large-postprocessing_0_2 (device 0)"
I0807 13:44:47.601654 28 backend_model_instance.cc:772] "Starting backend thread for multilingual-e5-large-postprocessing_0_2 at nice 0 on device 0..."
I0807 13:44:47.603480 28 model.py:32] "Successfull postprocessor init!"
I0807 13:44:47.610639 28 model.py:32] "Successfull postprocessor init!"
I0807 13:44:47.614462 28 python_be.cc:2425] "TRITONBACKEND_ModelInstanceInitialize: instance initialization successful multilingual-e5-large-postprocessing_0_0 (device 0)"
I0807 13:44:47.616358 28 model.py:32] "Successfull postprocessor init!"
I0807 13:44:47.616387 28 backend_model_instance.cc:772] "Starting backend thread for multilingual-e5-large-postprocessing_0_0 at nice 0 on device 0..."
I0807 13:44:47.617868 28 model.py:32] "Successfull postprocessor init!"
I0807 13:44:47.639135 28 python_be.cc:2425] "TRITONBACKEND_ModelInstanceInitialize: instance initialization successful multilingual-e5-large-postprocessing_0_4 (device 0)"
I0807 13:44:47.641932 28 backend_model_instance.cc:772] "Starting backend thread for multilingual-e5-large-postprocessing_0_4 at nice 0 on device 0..."
I0807 13:44:47.644050 28 model.py:32] "Successfull postprocessor init!"
I0807 13:44:47.644195 28 model.py:32] "Successfull postprocessor init!"
I0807 13:44:47.649832 28 python_be.cc:2425] "TRITONBACKEND_ModelInstanceInitialize: instance initialization successful multilingual-e5-large-postprocessing_0_3 (device 0)"
I0807 13:44:47.651856 28 python_be.cc:2425] "TRITONBACKEND_ModelInstanceInitialize: instance initialization successful multilingual-e5-large-postprocessing_0_6 (device 0)"
I0807 13:44:47.652086 28 backend_model_instance.cc:772] "Starting backend thread for multilingual-e5-large-postprocessing_0_3 at nice 0 on device 0..."
I0807 13:44:47.653781 28 backend_model_instance.cc:772] "Starting backend thread for multilingual-e5-large-postprocessing_0_6 at nice 0 on device 0..."
I0807 13:44:47.656119 28 model.py:32] "Successfull postprocessor init!"
I0807 13:44:47.657726 28 model.py:32] "Successfull postprocessor init!"
I0807 13:44:47.662004 28 model.py:32] "Successfull postprocessor init!"
I0807 13:44:47.676125 28 python_be.cc:2425] "TRITONBACKEND_ModelInstanceInitialize: instance initialization successful multilingual-e5-large-postprocessing_0_8 (device 0)"
I0807 13:44:47.679894 28 backend_model_instance.cc:772] "Starting backend thread for multilingual-e5-large-postprocessing_0_8 at nice 0 on device 0..."
I0807 13:44:47.684793 28 python_be.cc:2425] "TRITONBACKEND_ModelInstanceInitialize: instance initialization successful multilingual-e5-large-postprocessing_0_5 (device 0)"
I0807 13:44:47.688246 28 backend_model_instance.cc:772] "Starting backend thread for multilingual-e5-large-postprocessing_0_5 at nice 0 on device 0..."
I0807 13:44:47.690337 28 python_be.cc:2425] "TRITONBACKEND_ModelInstanceInitialize: instance initialization successful multilingual-e5-large-postprocessing_0_9 (device 0)"
I0807 13:44:47.692002 28 backend_model_instance.cc:772] "Starting backend thread for multilingual-e5-large-postprocessing_0_9 at nice 0 on device 0..."
I0807 13:44:47.692075 28 python_be.cc:2425] "TRITONBACKEND_ModelInstanceInitialize: instance initialization successful multilingual-e5-large-postprocessing_0_1 (device 0)"
I0807 13:44:47.693673 28 backend_model_instance.cc:772] "Starting backend thread for multilingual-e5-large-postprocessing_0_1 at nice 0 on device 0..."
I0807 13:44:47.693006 28 python_be.cc:2425] "TRITONBACKEND_ModelInstanceInitialize: instance initialization successful multilingual-e5-large-postprocessing_0_7 (device 0)"
I0807 13:44:47.693892 28 backend_model_instance.cc:772] "Starting backend thread for multilingual-e5-large-postprocessing_0_7 at nice 0 on device 0..."
I0807 13:44:47.694335 28 model_lifecycle.cc:838] "successfully loaded 'multilingual-e5-large-postprocessing'"
I0807 13:44:49.756713 28 python_be.cc:2055] "model configuration:\n{\n    \"name\": \"multilingual-e5-large-preprocessing\",\n    \"platform\": \"\",\n    \"backend\": \"python\",\n    \"runtime\": \"\",\n    \"version_policy\": {\n        \"latest\": {\n            \"num_versions\": 1\n        }\n    },\n    \"max_batch_size\": 256,\n    \"input\": [\n        {\n            \"name\": \"text\",\n            \"data_type\": \"TYPE_STRING\",\n            \"format\": \"FORMAT_NONE\",\n            \"dims\": [\n                1\n            ],\n            \"is_shape_tensor\": false,\n            \"allow_ragged_batch\": false,\n            \"optional\": false\n        }\n    ],\n    \"output\": [\n        {\n            \"name\": \"output_attention_mask\",\n            \"data_type\": \"TYPE_INT64\",\n            \"dims\": [\n                512\n            ],\n            \"label_filename\": \"\",\n            \"is_shape_tensor\": false\n        },\n        {\n            \"name\": \"output_input_ids\",\n            \"data_type\": \"TYPE_INT64\",\n            \"dims\": [\n                512\n            ],\n            \"label_filename\": \"\",\n            \"is_shape_tensor\": false\n        }\n    ],\n    \"batch_input\": [],\n    \"batch_output\": [],\n    \"optimization\": {\n        \"priority\": \"PRIORITY_DEFAULT\",\n        \"input_pinned_memory\": {\n            \"enable\": true\n        },\n        \"output_pinned_memory\": {\n            \"enable\": true\n        },\n        \"gather_kernel_buffer_threshold\": 0,\n        \"eager_batching\": false\n    },\n    \"instance_group\": [\n        {\n            \"name\": \"multilingual-e5-large-preprocessing_0\",\n            \"kind\": \"KIND_CPU\",\n            \"count\": 10,\n            \"gpus\": [],\n            \"secondary_devices\": [],\n            \"profile\": [],\n            \"passive\": false,\n            \"host_policy\": \"\"\n        }\n    ],\n    \"default_model_filename\": \"model.py\",\n    \"cc_model_filenames\": {},\n    \"metric_tags\": {},\n    \"parameters\": {},\n    \"model_warmup\": []\n}"
I0807 13:44:49.757098 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-preprocessing/1/batchstrategy.so"
I0807 13:44:49.814993 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-preprocessing/batchstrategy.so"
I0807 13:44:49.871010 28 python_be.cc:2404] "TRITONBACKEND_ModelInstanceInitialize: multilingual-e5-large-preprocessing_0_0 (CPU device 0)"
I0807 13:44:49.871064 28 backend_model_instance.cc:69] "Creating instance multilingual-e5-large-preprocessing_0_0 on CPU using artifact 'model.py'"
I0807 13:44:49.871259 28 python_be.cc:2404] "TRITONBACKEND_ModelInstanceInitialize: multilingual-e5-large-preprocessing_0_1 (CPU device 0)"
I0807 13:44:49.871319 28 backend_model_instance.cc:69] "Creating instance multilingual-e5-large-preprocessing_0_1 on CPU using artifact 'model.py'"
I0807 13:44:49.871385 28 python_be.cc:2404] "TRITONBACKEND_ModelInstanceInitialize: multilingual-e5-large-preprocessing_0_2 (CPU device 0)"
I0807 13:44:49.871442 28 backend_model_instance.cc:69] "Creating instance multilingual-e5-large-preprocessing_0_2 on CPU using artifact 'model.py'"
I0807 13:44:49.871452 28 python_be.cc:2404] "TRITONBACKEND_ModelInstanceInitialize: multilingual-e5-large-preprocessing_0_3 (CPU device 0)"
I0807 13:44:49.871499 28 backend_model_instance.cc:69] "Creating instance multilingual-e5-large-preprocessing_0_3 on CPU using artifact 'model.py'"
I0807 13:44:49.871572 28 python_be.cc:2404] "TRITONBACKEND_ModelInstanceInitialize: multilingual-e5-large-preprocessing_0_4 (CPU device 0)"
I0807 13:44:49.871604 28 backend_model_instance.cc:69] "Creating instance multilingual-e5-large-preprocessing_0_4 on CPU using artifact 'model.py'"
I0807 13:44:49.871718 28 python_be.cc:2404] "TRITONBACKEND_ModelInstanceInitialize: multilingual-e5-large-preprocessing_0_5 (CPU device 0)"
I0807 13:44:49.871740 28 backend_model_instance.cc:69] "Creating instance multilingual-e5-large-preprocessing_0_5 on CPU using artifact 'model.py'"
I0807 13:44:49.871809 28 python_be.cc:2404] "TRITONBACKEND_ModelInstanceInitialize: multilingual-e5-large-preprocessing_0_6 (CPU device 0)"
I0807 13:44:49.871833 28 backend_model_instance.cc:69] "Creating instance multilingual-e5-large-preprocessing_0_6 on CPU using artifact 'model.py'"
I0807 13:44:49.871943 28 python_be.cc:2404] "TRITONBACKEND_ModelInstanceInitialize: multilingual-e5-large-preprocessing_0_7 (CPU device 0)"
I0807 13:44:49.871964 28 backend_model_instance.cc:69] "Creating instance multilingual-e5-large-preprocessing_0_7 on CPU using artifact 'model.py'"
I0807 13:44:49.872838 28 python_be.cc:2404] "TRITONBACKEND_ModelInstanceInitialize: multilingual-e5-large-preprocessing_0_9 (CPU device 0)"
I0807 13:44:49.872854 28 backend_model_instance.cc:69] "Creating instance multilingual-e5-large-preprocessing_0_9 on CPU using artifact 'model.py'"
I0807 13:44:49.873013 28 stub_launcher.cc:385] "Starting Python backend stub:  exec /opt/tritonserver/backends/python/triton_python_backend_stub /tmp/folderW5fXFM/1/model.py triton_python_backend_shm_region_05ab4f26-6d2c-491d-8594-ddbfdd986388 1048576 1048576 28 /opt/tritonserver/backends/python 336 multilingual-e5-large-preprocessing_0_0 DEFAULT"
I0807 13:44:49.873198 28 python_be.cc:2404] "TRITONBACKEND_ModelInstanceInitialize: multilingual-e5-large-preprocessing_0_8 (CPU device 0)"
I0807 13:44:49.873220 28 backend_model_instance.cc:69] "Creating instance multilingual-e5-large-preprocessing_0_8 on CPU using artifact 'model.py'"
I0807 13:44:49.873360 28 stub_launcher.cc:385] "Starting Python backend stub:  exec /opt/tritonserver/backends/python/triton_python_backend_stub /tmp/folderW5fXFM/1/model.py triton_python_backend_shm_region_41214f1d-0d7f-4b2a-af24-2939fbb070c2 1048576 1048576 28 /opt/tritonserver/backends/python 336 multilingual-e5-large-preprocessing_0_6 DEFAULT"
I0807 13:44:49.873584 28 stub_launcher.cc:385] "Starting Python backend stub:  exec /opt/tritonserver/backends/python/triton_python_backend_stub /tmp/folderW5fXFM/1/model.py triton_python_backend_shm_region_b4477d3d-4b36-4c4b-9217-570ea56a7b4d 1048576 1048576 28 /opt/tritonserver/backends/python 336 multilingual-e5-large-preprocessing_0_1 DEFAULT"
I0807 13:44:49.873637 28 stub_launcher.cc:385] "Starting Python backend stub:  exec /opt/tritonserver/backends/python/triton_python_backend_stub /tmp/folderW5fXFM/1/model.py triton_python_backend_shm_region_770299b3-da52-451b-a8b0-c98cd66fd6fb 1048576 1048576 28 /opt/tritonserver/backends/python 336 multilingual-e5-large-preprocessing_0_4 DEFAULT"
I0807 13:44:49.873776 28 stub_launcher.cc:385] "Starting Python backend stub:  exec /opt/tritonserver/backends/python/triton_python_backend_stub /tmp/folderW5fXFM/1/model.py triton_python_backend_shm_region_5443bbfc-31ef-4c9d-b835-26517d0591be 1048576 1048576 28 /opt/tritonserver/backends/python 336 multilingual-e5-large-preprocessing_0_3 DEFAULT"
I0807 13:44:49.873788 28 stub_launcher.cc:385] "Starting Python backend stub:  exec /opt/tritonserver/backends/python/triton_python_backend_stub /tmp/folderW5fXFM/1/model.py triton_python_backend_shm_region_3587695b-7e3f-48df-893d-95d8e08257fa 1048576 1048576 28 /opt/tritonserver/backends/python 336 multilingual-e5-large-preprocessing_0_7 DEFAULT"
I0807 13:44:49.873807 28 stub_launcher.cc:385] "Starting Python backend stub:  exec /opt/tritonserver/backends/python/triton_python_backend_stub /tmp/folderW5fXFM/1/model.py triton_python_backend_shm_region_63985724-4157-47e6-95fd-1bb023e485e9 1048576 1048576 28 /opt/tritonserver/backends/python 336 multilingual-e5-large-preprocessing_0_2 DEFAULT"
I0807 13:44:49.873942 28 stub_launcher.cc:385] "Starting Python backend stub:  exec /opt/tritonserver/backends/python/triton_python_backend_stub /tmp/folderW5fXFM/1/model.py triton_python_backend_shm_region_d0ae0eb0-120c-4c7f-a4b1-74b637dea535 1048576 1048576 28 /opt/tritonserver/backends/python 336 multilingual-e5-large-preprocessing_0_5 DEFAULT"
I0807 13:44:49.873931 28 stub_launcher.cc:385] "Starting Python backend stub:  exec /opt/tritonserver/backends/python/triton_python_backend_stub /tmp/folderW5fXFM/1/model.py triton_python_backend_shm_region_3b62c674-c808-46c3-9835-ccf5cc53e04c 1048576 1048576 28 /opt/tritonserver/backends/python 336 multilingual-e5-large-preprocessing_0_9 DEFAULT"
I0807 13:44:49.874110 28 stub_launcher.cc:385] "Starting Python backend stub:  exec /opt/tritonserver/backends/python/triton_python_backend_stub /tmp/folderW5fXFM/1/model.py triton_python_backend_shm_region_0dbd4afa-1113-4b18-8002-8fd8826dbff3 1048576 1048576 28 /opt/tritonserver/backends/python 336 multilingual-e5-large-preprocessing_0_8 DEFAULT"
/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
I0807 13:44:55.356590 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-onnx/1/libtriton_onnxruntime.so"
I0807 13:44:55.410554 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-onnx/libtriton_onnxruntime.so"
I0807 13:44:55.467066 28 backend_model.cc:503] "Adding default backend config setting: default-max-batch-size,4"
I0807 13:44:55.467152 28 shared_library.cc:112] "OpenLibraryHandle: /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so"
I0807 13:44:55.472870 28 onnxruntime.cc:2789] "TRITONBACKEND_Initialize: onnxruntime"
I0807 13:44:55.472924 28 onnxruntime.cc:2799] "Triton TRITONBACKEND API version: 1.19"
I0807 13:44:55.472953 28 onnxruntime.cc:2805] "'onnxruntime' TRITONBACKEND API version: 1.19"
I0807 13:44:55.472975 28 onnxruntime.cc:2835] "backend configuration:\n{\"cmdline\":{\"auto-complete-config\":\"true\",\"backend-directory\":\"/opt/tritonserver/backends\",\"min-compute-capability\":\"6.000000\",\"default-max-batch-size\":\"4\"}}"
I0807 13:44:55.520158 28 onnxruntime.cc:3071] "TRITONBACKEND_GetBackendAttribute: setting attributes"
I0807 13:44:55.522237 28 onnxruntime.cc:2900] "TRITONBACKEND_ModelInitialize: multilingual-e5-large-onnx (version 1)"
I0807 13:44:55.523267 28 onnxruntime.cc:873] "skipping model configuration auto-complete for 'multilingual-e5-large-onnx': inputs and outputs already specified"
I0807 13:44:55.524697 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-onnx/1/batchstrategy.so"
I0807 13:44:55.578401 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/multilingual-e5-large-onnx/batchstrategy.so"
I0807 13:44:55.635728 28 onnxruntime.cc:2965] "TRITONBACKEND_ModelInstanceInitialize: onnx_gpu_group_0 (GPU device 0)"
I0807 13:44:55.636909 28 backend_model_instance.cc:106] "Creating instance onnx_gpu_group_0 on GPU 0 (8.0) using artifact 'model.onnx'"
2024-08-07 13:44:55.696156225 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:59 CreateTensorRTCustomOpDomainList] [TensorRT EP] Getting all registered TRT plugins from TRT plugin registry ...
2024-08-07 13:44:55.696363882 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] CaskDeconvV2RunnerWeightsTransformerPlugin, version : 1
2024-08-07 13:44:55.696379590 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] CaskDeconvV1RunnerWeightsTransformerPlugin, version : 1
2024-08-07 13:44:55.696392122 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] CaskConvolutionRunnerWeightsTransformerPlugin, version : 1
2024-08-07 13:44:55.696398608 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] CaskFlattenConvolutionRunnerWeightsTransformerPlugin, version : 1
2024-08-07 13:44:55.696404337 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] CaskConvActPoolWeightsTransformerPlugin, version : 1
2024-08-07 13:44:55.696410103 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] CaskDepSepConvWeightsTransformerPlugin, version : 1
2024-08-07 13:44:55.696416670 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] MyelinWeightsTransformPlugin, version : 1
2024-08-07 13:44:55.696422688 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] DisentangledAttention_TRT, version : 1
2024-08-07 13:44:55.696428389 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] CustomEmbLayerNormPluginDynamic, version : 1
2024-08-07 13:44:55.696434293 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] CustomEmbLayerNormPluginDynamic, version : 2
2024-08-07 13:44:55.696439739 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] CustomEmbLayerNormPluginDynamic, version : 3
2024-08-07 13:44:55.696445372 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] CustomFCPluginDynamic, version : 1
2024-08-07 13:44:55.696450741 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] CustomGeluPluginDynamic, version : 1
2024-08-07 13:44:55.696456899 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] GroupNormalizationPlugin, version : 1
2024-08-07 13:44:55.696467792 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] CustomSkipLayerNormPluginDynamic, version : 3
2024-08-07 13:44:55.696473718 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] CustomSkipLayerNormPluginDynamic, version : 4
2024-08-07 13:44:55.696479228 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] CustomSkipLayerNormPluginDynamic, version : 1
2024-08-07 13:44:55.696484347 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] CustomSkipLayerNormPluginDynamic, version : 2
2024-08-07 13:44:55.696489428 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] RnRes2Br1Br2c_TRT, version : 1
2024-08-07 13:44:55.696495350 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] RnRes2Br1Br2c_TRT, version : 2
2024-08-07 13:44:55.696500843 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] RnRes2Br2bBr2c_TRT, version : 1
2024-08-07 13:44:55.696506491 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] RnRes2Br2bBr2c_TRT, version : 2
2024-08-07 13:44:55.696512161 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] RnRes2FullFusion_TRT, version : 1
2024-08-07 13:44:55.696517842 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] SingleStepLSTMPlugin, version : 1
2024-08-07 13:44:55.696523999 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] CustomQKVToContextPluginDynamic, version : 3
2024-08-07 13:44:55.696529903 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] CustomQKVToContextPluginDynamic, version : 1
2024-08-07 13:44:55.696535561 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] CustomQKVToContextPluginDynamic, version : 2
2024-08-07 13:44:55.696540767 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] DLRM_BOTTOM_MLP_TRT, version : 1
2024-08-07 13:44:55.696546275 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] SmallTileGEMM_TRT, version : 1
2024-08-07 13:44:55.696551867 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] RNNTEncoderPlugin, version : 1
2024-08-07 13:44:55.696562481 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] BatchedNMSDynamic_TRT, version : 1
2024-08-07 13:44:55.696568573 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] BatchedNMS_TRT, version : 1
2024-08-07 13:44:55.696574166 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] BatchTilePlugin_TRT, version : 1
2024-08-07 13:44:55.696579646 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] Clip_TRT, version : 1
2024-08-07 13:44:55.696584966 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] CoordConvAC, version : 1
2024-08-07 13:44:55.696590290 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] CropAndResizeDynamic, version : 1
2024-08-07 13:44:55.696596270 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] CropAndResize, version : 1
2024-08-07 13:44:55.696601732 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] DecodeBbox3DPlugin, version : 1
2024-08-07 13:44:55.696607149 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] DetectionLayer_TRT, version : 1
2024-08-07 13:44:55.696613037 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] EfficientNMS_Explicit_TF_TRT, version : 1
2024-08-07 13:44:55.696618584 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] EfficientNMS_Implicit_TF_TRT, version : 1
2024-08-07 13:44:55.696627167 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] EfficientNMS_ONNX_TRT, version : 1
2024-08-07 13:44:55.696635023 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] EfficientNMS_TRT, version : 1
2024-08-07 13:44:55.696640564 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] FlattenConcat_TRT, version : 1
2024-08-07 13:44:55.696645885 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] GenerateDetection_TRT, version : 1
2024-08-07 13:44:55.696651351 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] GridAnchor_TRT, version : 1
2024-08-07 13:44:55.696656892 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] GridAnchorRect_TRT, version : 1
2024-08-07 13:44:55.696662327 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] InstanceNormalization_TRT, version : 1
2024-08-07 13:44:55.696667794 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] InstanceNormalization_TRT, version : 2
2024-08-07 13:44:55.696672991 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] LReLU_TRT, version : 1
2024-08-07 13:44:55.696678254 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] ModulatedDeformConv2d, version : 1
2024-08-07 13:44:55.696683725 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] MultilevelCropAndResize_TRT, version : 1
2024-08-07 13:44:55.696694537 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] MultilevelProposeROI_TRT, version : 1
2024-08-07 13:44:55.696700269 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] MultiscaleDeformableAttnPlugin_TRT, version : 1
2024-08-07 13:44:55.696705894 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] NMSDynamic_TRT, version : 1
2024-08-07 13:44:55.696711473 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] NMS_TRT, version : 1
2024-08-07 13:44:55.696717825 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] Normalize_TRT, version : 1
2024-08-07 13:44:55.696723054 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] PillarScatterPlugin, version : 1
2024-08-07 13:44:55.696728545 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] PriorBox_TRT, version : 1
2024-08-07 13:44:55.696733853 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] ProposalDynamic, version : 1
2024-08-07 13:44:55.696739375 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] ProposalLayer_TRT, version : 1
2024-08-07 13:44:55.696744868 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] Proposal, version : 1
2024-08-07 13:44:55.696750141 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] PyramidROIAlign_TRT, version : 1
2024-08-07 13:44:55.696755678 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] Region_TRT, version : 1
2024-08-07 13:44:55.696766630 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] Reorg_TRT, version : 2
2024-08-07 13:44:55.696772388 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] Reorg_TRT, version : 1
2024-08-07 13:44:55.696777559 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] ResizeNearest_TRT, version : 1
2024-08-07 13:44:55.696783268 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] ROIAlign_TRT, version : 1
2024-08-07 13:44:55.696788427 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] RPROI_TRT, version : 1
2024-08-07 13:44:55.696793764 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] ScatterElements, version : 1
2024-08-07 13:44:55.696798909 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] ScatterND, version : 1
2024-08-07 13:44:55.696805282 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] SpecialSlice_TRT, version : 1
2024-08-07 13:44:55.696810853 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] Split, version : 1
2024-08-07 13:44:55.696816091 [V:onnxruntime:log, tensorrt_execution_provider_custom_ops.cc:70 CreateTensorRTCustomOpDomainList] [TensorRT EP] VoxelGeneratorPlugin, version : 1
I0807 13:44:55.696832 28 onnxruntime.cc:705] "TensorRT Execution Accelerator is set for 'multilingual-e5-large-onnx' on device 0"
I0807 13:44:55.711334 28 onnxruntime.cc:760] "CUDA Execution Accelerator is set for 'multilingual-e5-large-onnx' on device 0"
2024-08-07 13:44:55.711392400 [I:onnxruntime:, inference_session.cc:533 TraceSessionOptions] Session Options {  execution_mode:0 execution_order:DEFAULT enable_profiling:0 optimized_model_filepath: enable_mem_pattern:1 enable_mem_reuse:1 enable_cpu_mem_arena:1 profile_file_prefix:onnxruntime_profile_ session_logid: session_log_severity_level:-1 session_log_verbosity_level:0 max_num_graph_transformation_steps:10 graph_optimization_level:3 intra_op_param:OrtThreadPoolParams { thread_pool_size: 0 auto_set_affinity: 0 allow_spinning: 1 dynamic_block_base_: 0 stack_size: 0 affinity_str:  set_denormal_as_zero: 0 } inter_op_param:OrtThreadPoolParams { thread_pool_size: 0 auto_set_affinity: 0 allow_spinning: 1 dynamic_block_base_: 0 stack_size: 0 affinity_str:  set_denormal_as_zero: 0 } use_per_session_threads:1 thread_pool_allow_spinning:1 use_deterministic_compute:0 config_options: {  } }
2024-08-07 13:44:55.711411306 [I:onnxruntime:, inference_session.cc:433 operator()] Flush-to-zero and denormal-as-zero are off
2024-08-07 13:44:55.711420668 [I:onnxruntime:, inference_session.cc:441 ConstructorCommon] Creating and using per session threadpools since use_per_session_threads_ is true
2024-08-07 13:44:55.711429566 [I:onnxruntime:, inference_session.cc:459 ConstructorCommon] Dynamic block base set to 0
2024-08-07 13:44:55.714103821 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2298, index: 0, mask: {1, 65, }
2024-08-07 13:44:55.714141904 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2299, index: 1, mask: {2, 66, }
2024-08-07 13:44:55.714260499 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2300, index: 2, mask: {3, 67, }
2024-08-07 13:44:55.714317119 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2302, index: 4, mask: {5, 69, }
2024-08-07 13:44:55.714353020 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2301, index: 3, mask: {4, 68, }
2024-08-07 13:44:55.714495194 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2303, index: 5, mask: {6, 70, }
2024-08-07 13:44:55.714512650 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2304, index: 6, mask: {7, 71, }
2024-08-07 13:44:55.714633651 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2305, index: 7, mask: {8, 72, }
2024-08-07 13:44:55.714742408 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2306, index: 8, mask: {9, 73, }
2024-08-07 13:44:55.715268077 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2307, index: 9, mask: {10, 74, }
2024-08-07 13:44:55.715418224 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2308, index: 10, mask: {11, 75, }
2024-08-07 13:44:55.715434617 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2309, index: 11, mask: {12, 76, }
2024-08-07 13:44:55.715706557 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2311, index: 13, mask: {14, 78, }
2024-08-07 13:44:55.715710697 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2310, index: 12, mask: {13, 77, }
2024-08-07 13:44:55.715870807 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2312, index: 14, mask: {15, 79, }
2024-08-07 13:44:55.715947576 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2314, index: 16, mask: {17, 81, }
2024-08-07 13:44:55.716018671 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2313, index: 15, mask: {16, 80, }
2024-08-07 13:44:55.716532922 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2315, index: 17, mask: {18, 82, }
2024-08-07 13:44:55.716610705 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2316, index: 18, mask: {19, 83, }
2024-08-07 13:44:55.716816239 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2317, index: 19, mask: {20, 84, }
2024-08-07 13:44:55.717339694 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2319, index: 21, mask: {22, 86, }
2024-08-07 13:44:55.717444612 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2321, index: 23, mask: {24, 88, }
2024-08-07 13:44:55.717335199 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2318, index: 20, mask: {21, 85, }
2024-08-07 13:44:55.717493347 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2320, index: 22, mask: {23, 87, }
2024-08-07 13:44:55.717716778 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2322, index: 24, mask: {25, 89, }
2024-08-07 13:44:55.717810672 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2323, index: 25, mask: {26, 90, }
2024-08-07 13:44:55.717889735 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2324, index: 26, mask: {27, 91, }
2024-08-07 13:44:55.717991336 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2325, index: 27, mask: {28, 92, }
2024-08-07 13:44:55.718603430 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2327, index: 29, mask: {30, 94, }
2024-08-07 13:44:55.718573001 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2326, index: 28, mask: {29, 93, }
2024-08-07 13:44:55.718966752 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2329, index: 31, mask: {32, 96, }
2024-08-07 13:44:55.718926480 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2328, index: 30, mask: {31, 95, }
2024-08-07 13:44:55.719102440 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2331, index: 33, mask: {34, 98, }
2024-08-07 13:44:55.719299388 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2332, index: 34, mask: {35, 99, }
2024-08-07 13:44:55.719304309 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2330, index: 32, mask: {33, 97, }
2024-08-07 13:44:55.719366814 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2333, index: 35, mask: {36, 100, }
2024-08-07 13:44:55.719971768 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2334, index: 36, mask: {37, 101, }
2024-08-07 13:44:55.720101713 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2335, index: 37, mask: {38, 102, }
2024-08-07 13:44:55.720163547 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2336, index: 38, mask: {39, 103, }
2024-08-07 13:44:55.720314586 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2337, index: 39, mask: {40, 104, }
2024-08-07 13:44:55.720811330 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2339, index: 41, mask: {42, 106, }
2024-08-07 13:44:55.720939264 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2340, index: 42, mask: {43, 107, }
2024-08-07 13:44:55.720950956 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2341, index: 43, mask: {44, 108, }
2024-08-07 13:44:55.721045324 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2342, index: 44, mask: {45, 109, }
2024-08-07 13:44:55.721375295 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2343, index: 45, mask: {46, 110, }
2024-08-07 13:44:55.721484250 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2346, index: 48, mask: {49, 113, }
2024-08-07 13:44:55.721322015 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2344, index: 46, mask: {47, 111, }
2024-08-07 13:44:55.721527672 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2345, index: 47, mask: {48, 112, }
2024-08-07 13:44:55.722112418 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2348, index: 50, mask: {51, 115, }
2024-08-07 13:44:55.722123604 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2347, index: 49, mask: {50, 114, }
2024-08-07 13:44:55.722634497 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2349, index: 51, mask: {52, 116, }
2024-08-07 13:44:55.722996836 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2350, index: 52, mask: {53, 117, }
2024-08-07 13:44:55.723194655 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2351, index: 53, mask: {54, 118, }
2024-08-07 13:44:55.723158817 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2353, index: 55, mask: {56, 120, }
2024-08-07 13:44:55.723243856 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2352, index: 54, mask: {55, 119, }
2024-08-07 13:44:55.723334032 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2354, index: 56, mask: {57, 121, }
2024-08-07 13:44:55.723520985 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2355, index: 57, mask: {58, 122, }
2024-08-07 13:44:55.723779925 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2357, index: 59, mask: {60, 124, }
2024-08-07 13:44:55.723796421 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2356, index: 58, mask: {59, 123, }
2024-08-07 13:44:55.723851885 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2338, index: 40, mask: {41, 105, }
2024-08-07 13:44:55.723960299 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2359, index: 61, mask: {62, 126, }
2024-08-07 13:44:55.723915090 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2358, index: 60, mask: {61, 125, }
2024-08-07 13:44:55.724136990 [V:onnxruntime:log, env.cc:221 ThreadMain] pthread_setaffinity_np succeed for thread: 2360, index: 62, mask: {63, 127, }
2024-08-07 13:44:55.788565364 [V:onnxruntime:log, tensorrt_execution_provider.cc:1608 TensorrtExecutionProvider] [TensorRT EP] TensorRT provider options: device_id: 0, trt_max_partition_iterations: 1000, trt_min_subgraph_size: 1, trt_max_workspace_size: 8589934592, trt_fp16_enable: 1, trt_int8_enable: 0, trt_int8_calibration_cache_name: , int8_calibration_cache_available: 0, trt_int8_use_native_tensorrt_calibration_table: 0, trt_dla_enable: 0, trt_dla_core: 0, trt_dump_subgraphs: 0, trt_engine_cache_enable: 0, trt_cache_path: , trt_global_cache_path: , trt_engine_decryption_enable: 0, trt_engine_decryption_lib_path: , trt_force_sequential_engine_build: 0, trt_context_memory_sharing_enable: 0, trt_layer_norm_fp32_fallback: 0, trt_build_heuristics_enable: 0, trt_sparsity_enable: 0, trt_builder_optimization_level: 3, trt_auxiliary_streams: -1, trt_tactic_sources: , trt_profile_min_shapes: , trt_profile_max_shapes: , trt_profile_opt_shapes: , trt_cuda_graph_enable: 0, trt_dump_ep_context_model: 0, trt_ep_context_file_path: , trt_ep_context_embed_mode: 0, trt_cache_prefix:
2024-08-07 13:44:55.789643562 [I:onnxruntime:, inference_session.cc:1602 Initialize] Initializing session.
2024-08-07 13:44:55.789655996 [I:onnxruntime:, inference_session.cc:1639 Initialize] Adding default CPU execution provider.
2024-08-07 13:44:55.789681602 [I:onnxruntime:log, bfc_arena.cc:29 BFCArena] Creating BFCArena for Cuda with following configs: initial_chunk_size_bytes: 1048576 max_dead_bytes_per_chunk: 134217728 initial_growth_chunk_size_bytes: 2097152 max_power_of_two_extend_bytes: 1073741824 memory limit: 18446744073709551615 arena_extend_strategy: 0
2024-08-07 13:44:55.789689375 [V:onnxruntime:log, bfc_arena.cc:66 BFCArena] Creating 21 bins of max chunk size 256 to 268435456
2024-08-07 13:44:55.789696687 [I:onnxruntime:log, bfc_arena.cc:29 BFCArena] Creating BFCArena for CudaPinned with following configs: initial_chunk_size_bytes: 1048576 max_dead_bytes_per_chunk: 134217728 initial_growth_chunk_size_bytes: 2097152 max_power_of_two_extend_bytes: 1073741824 memory limit: 18446744073709551615 arena_extend_strategy: 0
2024-08-07 13:44:55.789701845 [V:onnxruntime:log, bfc_arena.cc:66 BFCArena] Creating 21 bins of max chunk size 256 to 268435456
2024-08-07 13:44:55.789715026 [I:onnxruntime:log, bfc_arena.cc:29 BFCArena] Creating BFCArena for Cuda with following configs: initial_chunk_size_bytes: 1048576 max_dead_bytes_per_chunk: 134217728 initial_growth_chunk_size_bytes: 2097152 max_power_of_two_extend_bytes: 1073741824 memory limit: 18446744073709551615 arena_extend_strategy: 0
2024-08-07 13:44:55.789720835 [V:onnxruntime:log, bfc_arena.cc:66 BFCArena] Creating 21 bins of max chunk size 256 to 268435456
2024-08-07 13:44:55.789727898 [I:onnxruntime:log, bfc_arena.cc:29 BFCArena] Creating BFCArena for CudaPinned with following configs: initial_chunk_size_bytes: 1048576 max_dead_bytes_per_chunk: 134217728 initial_growth_chunk_size_bytes: 2097152 max_power_of_two_extend_bytes: 1073741824 memory limit: 18446744073709551615 arena_extend_strategy: 0
2024-08-07 13:44:55.789733006 [V:onnxruntime:log, bfc_arena.cc:66 BFCArena] Creating 21 bins of max chunk size 256 to 268435456
2024-08-07 13:44:55.789741580 [I:onnxruntime:log, bfc_arena.cc:29 BFCArena] Creating BFCArena for Cpu with following configs: initial_chunk_size_bytes: 1048576 max_dead_bytes_per_chunk: 134217728 initial_growth_chunk_size_bytes: 2097152 max_power_of_two_extend_bytes: 1073741824 memory limit: 18446744073709551615 arena_extend_strategy: 0
2024-08-07 13:44:55.789747211 [V:onnxruntime:log, bfc_arena.cc:66 BFCArena] Creating 21 bins of max chunk size 256 to 268435456
2024-08-07 13:44:55.792889427 [I:onnxruntime:, graph_partitioner.cc:900 InlineFunctionsAOT] This model does not have any local functions defined. AOT Inlining is not performed
2024-08-07 13:44:55.793539131 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer EnsureUniqueDQForNodeUnit modified: 0 with status: OK
2024-08-07 13:44:55.794473129 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer Level1_RuleBasedTransformer modified: 0 with status: OK
2024-08-07 13:44:55.794908658 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer DoubleQDQPairsRemover modified: 0 with status: OK
2024-08-07 13:44:55.799748935 [I:onnxruntime:, constant_sharing.cc:248 ApplyImpl] Total shared scalar initializer count: 754
2024-08-07 13:44:55.799789787 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer ConstantSharing modified: 1 with status: OK
2024-08-07 13:44:55.814319679 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer ShapeInputMerge modified: 0 with status: OK
2024-08-07 13:44:55.832850583 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer CommonSubexpressionElimination modified: 1 with status: OK
2024-08-07 13:44:55.853515384 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer ConstantFolding modified: 1 with status: OK
2024-08-07 13:44:55.866142964 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/1/Shape_3_output_0'. It is no longer used by any node.
2024-08-07 13:44:55.866159290 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/Shape_2_output_0'. It is no longer used by any node.
2024-08-07 13:44:55.866165589 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/1/Constant_8_output_0'. It is no longer used by any node.
2024-08-07 13:44:55.867016536 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer MatMulAddFusion modified: 0 with status: OK
2024-08-07 13:44:55.867421823 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.0/attention/self/Reshape_output_0
2024-08-07 13:44:55.867447071 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.0/attention/self/Reshape_2_output_0
2024-08-07 13:44:55.867466344 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.0/attention/self/Reshape_1_output_0
2024-08-07 13:44:55.867487780 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.0/attention/self/Reshape_3_output_0
2024-08-07 13:44:55.867507301 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.1/attention/self/Reshape_output_0
2024-08-07 13:44:55.867524734 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.1/attention/self/Reshape_2_output_0
2024-08-07 13:44:55.867543009 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.1/attention/self/Reshape_1_output_0
2024-08-07 13:44:55.867564578 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.1/attention/self/Reshape_3_output_0
2024-08-07 13:44:55.867593304 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.2/attention/self/Reshape_output_0
2024-08-07 13:44:55.867611375 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.2/attention/self/Reshape_2_output_0
2024-08-07 13:44:55.867629427 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.2/attention/self/Reshape_1_output_0
2024-08-07 13:44:55.867651955 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.2/attention/self/Reshape_3_output_0
2024-08-07 13:44:55.867671176 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.3/attention/self/Reshape_output_0
2024-08-07 13:44:55.867688829 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.3/attention/self/Reshape_2_output_0
2024-08-07 13:44:55.867706701 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.3/attention/self/Reshape_1_output_0
2024-08-07 13:44:55.867725858 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.3/attention/self/Reshape_3_output_0
2024-08-07 13:44:55.867745228 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.4/attention/self/Reshape_output_0
2024-08-07 13:44:55.867762579 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.4/attention/self/Reshape_2_output_0
2024-08-07 13:44:55.867780112 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.4/attention/self/Reshape_1_output_0
2024-08-07 13:44:55.867799628 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.4/attention/self/Reshape_3_output_0
2024-08-07 13:44:55.867818819 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.5/attention/self/Reshape_output_0
2024-08-07 13:44:55.867836264 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.5/attention/self/Reshape_2_output_0
2024-08-07 13:44:55.867853657 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.5/attention/self/Reshape_1_output_0
2024-08-07 13:44:55.867872441 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.5/attention/self/Reshape_3_output_0
2024-08-07 13:44:55.867890954 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.6/attention/self/Reshape_output_0
2024-08-07 13:44:55.867908271 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.6/attention/self/Reshape_2_output_0
2024-08-07 13:44:55.867925498 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.6/attention/self/Reshape_1_output_0
2024-08-07 13:44:55.867944835 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.6/attention/self/Reshape_3_output_0
2024-08-07 13:44:55.867963729 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.7/attention/self/Reshape_output_0
2024-08-07 13:44:55.867981034 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.7/attention/self/Reshape_2_output_0
2024-08-07 13:44:55.867998618 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.7/attention/self/Reshape_1_output_0
2024-08-07 13:44:55.868018048 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.7/attention/self/Reshape_3_output_0
2024-08-07 13:44:55.868037509 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.8/attention/self/Reshape_output_0
2024-08-07 13:44:55.868054868 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.8/attention/self/Reshape_2_output_0
2024-08-07 13:44:55.868072524 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.8/attention/self/Reshape_1_output_0
2024-08-07 13:44:55.868094903 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.8/attention/self/Reshape_3_output_0
2024-08-07 13:44:55.868113599 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.9/attention/self/Reshape_output_0
2024-08-07 13:44:55.868130541 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.9/attention/self/Reshape_2_output_0
2024-08-07 13:44:55.868147798 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.9/attention/self/Reshape_1_output_0
2024-08-07 13:44:55.868167664 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.9/attention/self/Reshape_3_output_0
2024-08-07 13:44:55.868186850 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.10/attention/self/Reshape_output_0
2024-08-07 13:44:55.868204730 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.10/attention/self/Reshape_2_output_0
2024-08-07 13:44:55.868222374 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.10/attention/self/Reshape_1_output_0
2024-08-07 13:44:55.868242910 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.10/attention/self/Reshape_3_output_0
2024-08-07 13:44:55.868262100 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.11/attention/self/Reshape_output_0
2024-08-07 13:44:55.868279695 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.11/attention/self/Reshape_2_output_0
2024-08-07 13:44:55.868297094 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.11/attention/self/Reshape_1_output_0
2024-08-07 13:44:55.868316943 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.11/attention/self/Reshape_3_output_0
2024-08-07 13:44:55.868335782 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.12/attention/self/Reshape_output_0
2024-08-07 13:44:55.868353462 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.12/attention/self/Reshape_2_output_0
2024-08-07 13:44:55.868371154 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.12/attention/self/Reshape_1_output_0
2024-08-07 13:44:55.868390365 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.12/attention/self/Reshape_3_output_0
2024-08-07 13:44:55.868409416 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.13/attention/self/Reshape_output_0
2024-08-07 13:44:55.868427896 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.13/attention/self/Reshape_2_output_0
2024-08-07 13:44:55.868445390 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.13/attention/self/Reshape_1_output_0
2024-08-07 13:44:55.868464003 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.13/attention/self/Reshape_3_output_0
2024-08-07 13:44:55.868483107 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.14/attention/self/Reshape_output_0
2024-08-07 13:44:55.868500714 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.14/attention/self/Reshape_2_output_0
2024-08-07 13:44:55.868518691 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.14/attention/self/Reshape_1_output_0
2024-08-07 13:44:55.868537762 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.14/attention/self/Reshape_3_output_0
2024-08-07 13:44:55.868557076 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.15/attention/self/Reshape_output_0
2024-08-07 13:44:55.868575029 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.15/attention/self/Reshape_2_output_0
2024-08-07 13:44:55.868593435 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.15/attention/self/Reshape_1_output_0
2024-08-07 13:44:55.868613283 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.15/attention/self/Reshape_3_output_0
2024-08-07 13:44:55.868632371 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.16/attention/self/Reshape_output_0
2024-08-07 13:44:55.868650614 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.16/attention/self/Reshape_2_output_0
2024-08-07 13:44:55.868668449 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.16/attention/self/Reshape_1_output_0
2024-08-07 13:44:55.868687408 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.16/attention/self/Reshape_3_output_0
2024-08-07 13:44:55.868706429 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.17/attention/self/Reshape_output_0
2024-08-07 13:44:55.868723763 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.17/attention/self/Reshape_2_output_0
2024-08-07 13:44:55.868741377 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.17/attention/self/Reshape_1_output_0
2024-08-07 13:44:55.868760644 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.17/attention/self/Reshape_3_output_0
2024-08-07 13:44:55.868779418 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.18/attention/self/Reshape_output_0
2024-08-07 13:44:55.868796908 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.18/attention/self/Reshape_2_output_0
2024-08-07 13:44:55.868814708 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.18/attention/self/Reshape_1_output_0
2024-08-07 13:44:55.868834163 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.18/attention/self/Reshape_3_output_0
2024-08-07 13:44:55.868853829 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.19/attention/self/Reshape_output_0
2024-08-07 13:44:55.868870944 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.19/attention/self/Reshape_2_output_0
2024-08-07 13:44:55.868888514 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.19/attention/self/Reshape_1_output_0
2024-08-07 13:44:55.868907554 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.19/attention/self/Reshape_3_output_0
2024-08-07 13:44:55.868926343 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.20/attention/self/Reshape_output_0
2024-08-07 13:44:55.868943680 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.20/attention/self/Reshape_2_output_0
2024-08-07 13:44:55.868961074 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.20/attention/self/Reshape_1_output_0
2024-08-07 13:44:55.868979765 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.20/attention/self/Reshape_3_output_0
2024-08-07 13:44:55.868998594 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.21/attention/self/Reshape_output_0
2024-08-07 13:44:55.869016377 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.21/attention/self/Reshape_2_output_0
2024-08-07 13:44:55.869033638 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.21/attention/self/Reshape_1_output_0
2024-08-07 13:44:55.869052616 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.21/attention/self/Reshape_3_output_0
2024-08-07 13:44:55.869071348 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.22/attention/self/Reshape_output_0
2024-08-07 13:44:55.869088906 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.22/attention/self/Reshape_2_output_0
2024-08-07 13:44:55.869106394 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.22/attention/self/Reshape_1_output_0
2024-08-07 13:44:55.869125949 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.22/attention/self/Reshape_3_output_0
2024-08-07 13:44:55.869146125 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.23/attention/self/Reshape_output_0
2024-08-07 13:44:55.869163430 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.23/attention/self/Reshape_2_output_0
2024-08-07 13:44:55.869180972 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.23/attention/self/Reshape_1_output_0
2024-08-07 13:44:55.869199858 [I:onnxruntime:, reshape_fusion.cc:49 ApplyImpl] Fused reshape node: /0/auto_model/encoder/layer.23/attention/self/Reshape_3_output_0
2024-08-07 13:44:55.869208430 [I:onnxruntime:, reshape_fusion.cc:55 ApplyImpl] Total fused reshape node count: 96
2024-08-07 13:44:55.869214881 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer ReshapeFusion modified: 1 with status: OK
2024-08-07 13:44:55.879138310 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.23/attention/self/Constant_11_output_0'. It is no longer used by any node.
2024-08-07 13:44:55.879154315 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.23/attention/self/Constant_10_output_0'. It is no longer used by any node.
2024-08-07 13:44:55.879160471 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.3/attention/self/Constant_15_output_0'. It is no longer used by any node.
2024-08-07 13:44:55.879411932 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer FreeDimensionOverrideTransformer modified: 0 with status: OK
2024-08-07 13:44:55.879936819 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer QDQPropagationTransformer modified: 0 with status: OK
2024-08-07 13:44:55.880265239 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer EnsureUniqueDQForNodeUnit modified: 0 with status: OK
2024-08-07 13:44:55.880516825 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer RocmBlasAltImpl modified: 0 with status: OK
2024-08-07 13:44:55.882053570 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer TransposeOptimizer modified: 0 with status: OK
2024-08-07 13:44:55.882695282 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer Level1_RuleBasedTransformer modified: 0 with status: OK
2024-08-07 13:44:55.882987805 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer DoubleQDQPairsRemover modified: 0 with status: OK
2024-08-07 13:44:55.883277883 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer ShapeInputMerge modified: 0 with status: OK
2024-08-07 13:44:55.884763131 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer CommonSubexpressionElimination modified: 0 with status: OK
2024-08-07 13:44:55.885356158 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer ConstantFolding modified: 0 with status: OK
2024-08-07 13:44:55.885691981 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer MatMulAddFusion modified: 0 with status: OK
2024-08-07 13:44:55.885988043 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer ReshapeFusion modified: 0 with status: OK
2024-08-07 13:44:55.885996830 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer FreeDimensionOverrideTransformer modified: 0 with status: OK
2024-08-07 13:44:55.886411471 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer QDQPropagationTransformer modified: 0 with status: OK
2024-08-07 13:44:55.886722568 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer EnsureUniqueDQForNodeUnit modified: 0 with status: OK
2024-08-07 13:44:55.886968099 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer RocmBlasAltImpl modified: 0 with status: OK
2024-08-07 13:44:55.887222909 [I:onnxruntime:log, tensorrt_execution_provider_utils.h:546 TRTGenerateId] [TensorRT EP] Model name is model.onnx
I0807 13:44:57.678393 28 model.py:35] "Successfull init!"
I0807 13:44:57.678539 28 model.py:36] "Using fast version of tokenizer on RUST: True"
I0807 13:44:57.688339 28 python_be.cc:2425] "TRITONBACKEND_ModelInstanceInitialize: instance initialization successful multilingual-e5-large-preprocessing_0_3 (device 0)"
I0807 13:44:57.688692 28 backend_model_instance.cc:772] "Starting backend thread for multilingual-e5-large-preprocessing_0_3 at nice 0 on device 0..."
I0807 13:44:57.706735 28 model.py:35] "Successfull init!"
I0807 13:44:57.706843 28 model.py:36] "Using fast version of tokenizer on RUST: True"
I0807 13:44:57.711145 28 model.py:35] "Successfull init!"
I0807 13:44:57.711260 28 python_be.cc:2425] "TRITONBACKEND_ModelInstanceInitialize: instance initialization successful multilingual-e5-large-preprocessing_0_2 (device 0)"
I0807 13:44:57.711424 28 model.py:36] "Using fast version of tokenizer on RUST: True"
I0807 13:44:57.711827 28 backend_model_instance.cc:772] "Starting backend thread for multilingual-e5-large-preprocessing_0_2 at nice 0 on device 0..."
I0807 13:44:57.719421 28 python_be.cc:2425] "TRITONBACKEND_ModelInstanceInitialize: instance initialization successful multilingual-e5-large-preprocessing_0_7 (device 0)"
I0807 13:44:57.719650 28 backend_model_instance.cc:772] "Starting backend thread for multilingual-e5-large-preprocessing_0_7 at nice 0 on device 0..."
I0807 13:44:57.728961 28 model.py:35] "Successfull init!"
I0807 13:44:57.729059 28 model.py:36] "Using fast version of tokenizer on RUST: True"
I0807 13:44:57.732944 28 python_be.cc:2425] "TRITONBACKEND_ModelInstanceInitialize: instance initialization successful multilingual-e5-large-preprocessing_0_5 (device 0)"
I0807 13:44:57.733498 28 backend_model_instance.cc:772] "Starting backend thread for multilingual-e5-large-preprocessing_0_5 at nice 0 on device 0..."
I0807 13:44:57.749559 28 model.py:35] "Successfull init!"
I0807 13:44:57.749648 28 model.py:36] "Using fast version of tokenizer on RUST: True"
I0807 13:44:57.751949 28 model.py:35] "Successfull init!"
I0807 13:44:57.752044 28 model.py:36] "Using fast version of tokenizer on RUST: True"
I0807 13:44:57.755093 28 python_be.cc:2425] "TRITONBACKEND_ModelInstanceInitialize: instance initialization successful multilingual-e5-large-preprocessing_0_0 (device 0)"
I0807 13:44:57.755790 28 backend_model_instance.cc:772] "Starting backend thread for multilingual-e5-large-preprocessing_0_0 at nice 0 on device 0..."
I0807 13:44:57.757855 28 python_be.cc:2425] "TRITONBACKEND_ModelInstanceInitialize: instance initialization successful multilingual-e5-large-preprocessing_0_6 (device 0)"
I0807 13:44:57.758006 28 backend_model_instance.cc:772] "Starting backend thread for multilingual-e5-large-preprocessing_0_6 at nice 0 on device 0..."
I0807 13:44:57.760144 28 model.py:35] "Successfull init!"
I0807 13:44:57.760214 28 model.py:36] "Using fast version of tokenizer on RUST: True"
I0807 13:44:57.763918 28 python_be.cc:2425] "TRITONBACKEND_ModelInstanceInitialize: instance initialization successful multilingual-e5-large-preprocessing_0_9 (device 0)"
I0807 13:44:57.764426 28 backend_model_instance.cc:772] "Starting backend thread for multilingual-e5-large-preprocessing_0_9 at nice 0 on device 0..."
I0807 13:44:57.782297 28 model.py:35] "Successfull init!"
I0807 13:44:57.782388 28 model.py:36] "Using fast version of tokenizer on RUST: True"
I0807 13:44:57.786107 28 python_be.cc:2425] "TRITONBACKEND_ModelInstanceInitialize: instance initialization successful multilingual-e5-large-preprocessing_0_1 (device 0)"
I0807 13:44:57.786233 28 backend_model_instance.cc:772] "Starting backend thread for multilingual-e5-large-preprocessing_0_1 at nice 0 on device 0..."
I0807 13:44:57.795292 28 model.py:35] "Successfull init!"
I0807 13:44:57.795359 28 model.py:36] "Using fast version of tokenizer on RUST: True"
I0807 13:44:57.801796 28 python_be.cc:2425] "TRITONBACKEND_ModelInstanceInitialize: instance initialization successful multilingual-e5-large-preprocessing_0_4 (device 0)"
I0807 13:44:57.802656 28 backend_model_instance.cc:772] "Starting backend thread for multilingual-e5-large-preprocessing_0_4 at nice 0 on device 0..."
I0807 13:44:57.804053 28 model.py:35] "Successfull init!"
I0807 13:44:57.804133 28 model.py:36] "Using fast version of tokenizer on RUST: True"
I0807 13:44:57.807775 28 python_be.cc:2425] "TRITONBACKEND_ModelInstanceInitialize: instance initialization successful multilingual-e5-large-preprocessing_0_8 (device 0)"
I0807 13:44:57.807910 28 backend_model_instance.cc:772] "Starting backend thread for multilingual-e5-large-preprocessing_0_8 at nice 0 on device 0..."
I0807 13:44:57.808049 28 model_lifecycle.cc:838] "successfully loaded 'multilingual-e5-large-preprocessing'"
2024-08-07 13:44:59.072951539 [W:onnxruntime:log, tensorrt_execution_provider.h:84 log] [2024-08-07 13:44:59 WARNING] ModelImporter.cpp:420: Make sure input input_ids has Int64 binding.
2024-08-07 13:44:59.072987003 [W:onnxruntime:log, tensorrt_execution_provider.h:84 log] [2024-08-07 13:44:59 WARNING] ModelImporter.cpp:420: Make sure input attention_mask has Int64 binding.
2024-08-07 13:45:00.659127306 [I:onnxruntime:log, tensorrt_execution_provider.cc:1932 GetSubGraph] [TensorRT EP] TensorRT subgraph MetaDef name TRTKernel_graph_main_graph_18143363761047663204_0
2024-08-07 13:45:00.660305953 [I:onnxruntime:log, tensorrt_execution_provider.cc:1932 GetSubGraph] [TensorRT EP] TensorRT subgraph MetaDef name TRTKernel_graph_main_graph_18143363761047663204_0
2024-08-07 13:45:00.660428940 [I:onnxruntime:log, tensorrt_execution_provider.cc:2455 GetCapability] [TensorRT EP] Whole graph will run on TensorRT execution provider
2024-08-07 13:45:00.665935605 [W:onnxruntime:log, tensorrt_execution_provider.h:84 log] [2024-08-07 13:45:00 WARNING] ModelImporter.cpp:420: Make sure input input_ids has Int64 binding.
2024-08-07 13:45:00.665959667 [W:onnxruntime:log, tensorrt_execution_provider.h:84 log] [2024-08-07 13:45:00 WARNING] ModelImporter.cpp:420: Make sure input attention_mask has Int64 binding.
2024-08-07 13:45:02.073233707 [V:onnxruntime:log, tensorrt_execution_provider.cc:2718 CreateNodeComputeInfoFromGraph] [TensorRT EP] FP16 mode is enabled
2024-08-07 13:45:02.078567036 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.23/attention/self/Concat_3_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078584365 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.23/attention/self/Concat_1_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078589667 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.23/attention/self/Concat_2_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078593971 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.23/attention/self/Concat_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078598412 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.22/attention/self/Concat_2_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078602531 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.22/attention/self/Concat_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078606499 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.21/attention/self/Concat_3_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078610456 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.21/attention/self/Concat_1_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078615081 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.21/attention/self/Concat_2_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078619208 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.21/attention/self/Concat_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078623145 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.20/attention/self/Concat_3_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078627055 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.20/attention/self/Concat_1_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078631003 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.20/attention/self/Concat_2_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078634939 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.20/attention/self/Concat_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078638885 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.19/attention/self/Concat_3_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078642828 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.19/attention/self/Concat_1_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078646863 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.19/attention/self/Concat_2_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078651161 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.19/attention/self/Concat_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078655069 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.18/attention/self/Concat_3_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078659091 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.18/attention/self/Concat_1_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078662992 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.18/attention/self/Concat_2_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078666948 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.18/attention/self/Concat_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078670971 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.17/attention/self/Concat_3_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078675000 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.17/attention/self/Concat_1_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078679060 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.17/attention/self/Concat_2_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078683058 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.16/attention/self/Concat_3_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078686980 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.16/attention/self/Concat_1_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078690932 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.15/attention/self/Concat_3_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078694878 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.15/attention/self/Concat_1_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078698798 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.15/attention/self/Concat_2_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078702760 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.15/attention/self/Concat_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078706651 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.14/attention/self/Concat_3_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078710681 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.14/attention/self/Concat_1_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078715303 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.14/attention/self/Concat_2_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078719358 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.14/attention/self/Concat_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078723506 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.13/attention/self/Concat_3_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078727602 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.13/attention/self/Concat_1_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078731547 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.13/attention/self/Concat_2_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078735655 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.13/attention/self/Concat_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078739575 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.12/attention/self/Concat_3_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078743661 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.12/attention/self/Concat_1_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078747688 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.12/attention/self/Concat_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078751622 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.11/attention/self/Concat_1_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078755618 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.11/attention/self/Concat_2_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078759610 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.11/attention/self/Concat_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078763481 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.10/attention/self/Concat_3_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078767648 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.10/attention/self/Concat_1_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078771505 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.10/attention/self/Concat_2_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078775619 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.10/attention/self/Concat_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078779668 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.9/attention/self/Concat_2_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078783678 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.9/attention/self/Concat_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078787586 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.8/attention/self/Concat_3_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078791508 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.8/attention/self/Concat_1_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078795363 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.8/attention/self/Concat_2_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078799288 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.8/attention/self/Concat_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078803302 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.7/attention/self/Concat_3_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078807424 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.22/attention/self/Concat_1_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078811373 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.7/attention/self/Concat_1_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078815433 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.7/attention/self/Concat_2_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078819388 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.7/attention/self/Concat_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078823296 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.6/attention/self/Concat_3_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078827352 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.6/attention/self/Concat_1_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078831550 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.6/attention/self/Concat_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078835797 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.5/attention/self/Concat_3_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078839747 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.5/attention/self/Concat_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078844108 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.4/attention/self/Concat_3_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078848126 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.4/attention/self/Concat_1_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078852202 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.4/attention/self/Concat_2_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078856121 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.3/attention/self/Concat_3_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078859984 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.3/attention/self/Concat_1_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078863999 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.3/attention/self/Concat_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078867901 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.2/attention/self/Concat_3_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078871994 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.2/attention/self/Concat_2_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078875947 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.2/attention/self/Concat_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078880044 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.1/attention/self/Concat_3_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078883971 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.1/attention/self/Concat_1_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078887855 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.1/attention/self/Concat_2_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078891757 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.1/attention/self/Concat_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078895642 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.0/attention/self/Concat_3_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078899612 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.0/attention/self/Concat_2_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078903662 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/1/Mul_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078907747 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/1/ConstantOfShape_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078911770 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/ConstantOfShape_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078915785 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/1/Constant_9_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078920222 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::ReduceSum_3420'. It is no longer used by any node.
2024-08-07 13:45:02.078924215 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/1/Constant_7_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078928110 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/1/Constant_4_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078932316 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/1/Constant_3_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078936327 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/1/Constant_1_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078940327 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.23/output/LayerNorm/Constant_1_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078944328 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.23/output/LayerNorm/Constant_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078948290 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.23/intermediate/intermediate_act_fn/Constant_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078952774 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.23/attention/self/Constant_14_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078956707 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.23/attention/self/Constant_12_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078960727 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.22/intermediate/intermediate_act_fn/Constant_1_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078964702 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.18.attention.output.LayerNorm.bias'. It is no longer used by any node.
2024-08-07 13:45:02.078968610 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.4.output.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.078972675 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.9.attention.self.query.bias'. It is no longer used by any node.
2024-08-07 13:45:02.078976626 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3627'. It is no longer used by any node.
2024-08-07 13:45:02.078980587 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.17.output.LayerNorm.bias'. It is no longer used by any node.
2024-08-07 13:45:02.078984549 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3725'. It is no longer used by any node.
2024-08-07 13:45:02.078988532 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.22/intermediate/intermediate_act_fn/Constant_2_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.078992745 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3530'. It is no longer used by any node.
2024-08-07 13:45:02.078997220 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3464'. It is no longer used by any node.
2024-08-07 13:45:02.079001164 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.10.intermediate.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079005171 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.8.attention.self.key.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079009150 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.23.attention.output.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079013451 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3724'. It is no longer used by any node.
2024-08-07 13:45:02.079017524 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3544'. It is no longer used by any node.
2024-08-07 13:45:02.079021670 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3711'. It is no longer used by any node.
2024-08-07 13:45:02.079025843 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.6.output.LayerNorm.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079029725 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3584'. It is no longer used by any node.
2024-08-07 13:45:02.079033793 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.7.output.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079038148 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/Constant_11_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.079042092 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.12.intermediate.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079046020 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3715'. It is no longer used by any node.
2024-08-07 13:45:02.079050007 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.4.attention.output.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079053909 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3750'. It is no longer used by any node.
2024-08-07 13:45:02.079057835 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.18.output.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079061757 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3731'. It is no longer used by any node.
2024-08-07 13:45:02.079065654 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3718'. It is no longer used by any node.
2024-08-07 13:45:02.079069645 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3714'. It is no longer used by any node.
2024-08-07 13:45:02.079073641 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.6.attention.self.key.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079077768 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3455'. It is no longer used by any node.
2024-08-07 13:45:02.079082115 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3738'. It is no longer used by any node.
2024-08-07 13:45:02.079086151 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3701'. It is no longer used by any node.
2024-08-07 13:45:02.079090054 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3699'. It is no longer used by any node.
2024-08-07 13:45:02.079094070 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3751'. It is no longer used by any node.
2024-08-07 13:45:02.079098024 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.12.attention.self.key.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079102830 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.12.attention.self.value.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079106783 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3688'. It is no longer used by any node.
2024-08-07 13:45:02.079110709 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3687'. It is no longer used by any node.
2024-08-07 13:45:02.079114734 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3686'. It is no longer used by any node.
2024-08-07 13:45:02.079118681 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.14.attention.self.query.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079122644 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.21.attention.output.LayerNorm.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079127034 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3453'. It is no longer used by any node.
2024-08-07 13:45:02.079131578 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3649'. It is no longer used by any node.
2024-08-07 13:45:02.079135509 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3692'. It is no longer used by any node.
2024-08-07 13:45:02.079139451 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3647'. It is no longer used by any node.
2024-08-07 13:45:02.079143381 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3640'. It is no longer used by any node.
2024-08-07 13:45:02.079147327 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3637'. It is no longer used by any node.
2024-08-07 13:45:02.079151277 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.15.attention.output.LayerNorm.weight'. It is no longer used by any node.
2024-08-07 13:45:02.079155169 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.20.output.LayerNorm.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079159111 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3635'. It is no longer used by any node.
2024-08-07 13:45:02.079163050 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3633'. It is no longer used by any node.
2024-08-07 13:45:02.079167034 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3623'. It is no longer used by any node.
2024-08-07 13:45:02.079171208 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3660'. It is no longer used by any node.
2024-08-07 13:45:02.079175102 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3622'. It is no longer used by any node.
2024-08-07 13:45:02.079179114 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3620'. It is no longer used by any node.
2024-08-07 13:45:02.079183091 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.12.attention.output.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079187122 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3737'. It is no longer used by any node.
2024-08-07 13:45:02.079191109 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3610'. It is no longer used by any node.
2024-08-07 13:45:02.079195156 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3608'. It is no longer used by any node.
2024-08-07 13:45:02.079199061 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.11.attention.self.query.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079203319 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3601'. It is no longer used by any node.
2024-08-07 13:45:02.079207320 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.2.output.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079211354 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.3.attention.self.query.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079215358 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3597'. It is no longer used by any node.
2024-08-07 13:45:02.079219530 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.9.attention.self.key.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079223583 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.22.intermediate.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079227659 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3596'. It is no longer used by any node.
2024-08-07 13:45:02.079231675 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.11/attention/self/Concat_3_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.079235762 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3583'. It is no longer used by any node.
2024-08-07 13:45:02.079239765 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3581'. It is no longer used by any node.
2024-08-07 13:45:02.079243625 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3572'. It is no longer used by any node.
2024-08-07 13:45:02.079247470 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3571'. It is no longer used by any node.
2024-08-07 13:45:02.079251535 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.7.attention.output.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079255542 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3557'. It is no longer used by any node.
2024-08-07 13:45:02.079259615 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.8.attention.output.LayerNorm.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079263510 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3555'. It is no longer used by any node.
2024-08-07 13:45:02.079267345 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3549'. It is no longer used by any node.
2024-08-07 13:45:02.079271490 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3543'. It is no longer used by any node.
2024-08-07 13:45:02.079275383 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3533'. It is no longer used by any node.
2024-08-07 13:45:02.079279199 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3531'. It is no longer used by any node.
2024-08-07 13:45:02.079283099 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.3/attention/self/Concat_2_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.079287020 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3529'. It is no longer used by any node.
2024-08-07 13:45:02.079290967 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3520'. It is no longer used by any node.
2024-08-07 13:45:02.079294853 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3666'. It is no longer used by any node.
2024-08-07 13:45:02.079298784 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.5.output.LayerNorm.weight'. It is no longer used by any node.
2024-08-07 13:45:02.079302774 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.11.output.LayerNorm.weight'. It is no longer used by any node.
2024-08-07 13:45:02.079306679 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3518'. It is no longer used by any node.
2024-08-07 13:45:02.079310852 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3562'. It is no longer used by any node.
2024-08-07 13:45:02.079315109 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.23.attention.self.value.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079319026 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3705'. It is no longer used by any node.
2024-08-07 13:45:02.079323023 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3516'. It is no longer used by any node.
2024-08-07 13:45:02.079326890 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3741'. It is no longer used by any node.
2024-08-07 13:45:02.079330759 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3510'. It is no longer used by any node.
2024-08-07 13:45:02.079334574 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3505'. It is no longer used by any node.
2024-08-07 13:45:02.079338501 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3493'. It is no longer used by any node.
2024-08-07 13:45:02.079342590 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3542'. It is no longer used by any node.
2024-08-07 13:45:02.079346510 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3468'. It is no longer used by any node.
2024-08-07 13:45:02.079350655 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3490'. It is no longer used by any node.
2024-08-07 13:45:02.079354586 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3712'. It is no longer used by any node.
2024-08-07 13:45:02.079358622 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.0.attention.output.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079362468 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3480'. It is no longer used by any node.
2024-08-07 13:45:02.079366403 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.18.attention.self.value.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079370326 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3478'. It is no longer used by any node.
2024-08-07 13:45:02.079374244 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3477'. It is no longer used by any node.
2024-08-07 13:45:02.079378127 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3519'. It is no longer used by any node.
2024-08-07 13:45:02.079382076 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.16/attention/self/Concat_2_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.079386104 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3471'. It is no longer used by any node.
2024-08-07 13:45:02.079390097 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.11.output.LayerNorm.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079394092 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3441'. It is no longer used by any node.
2024-08-07 13:45:02.079398350 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.11.attention.self.value.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079402287 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3536'. It is no longer used by any node.
2024-08-07 13:45:02.079406394 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3559'. It is no longer used by any node.
2024-08-07 13:45:02.079410302 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3689'. It is no longer used by any node.
2024-08-07 13:45:02.079414195 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3546'. It is no longer used by any node.
2024-08-07 13:45:02.079418139 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.10.attention.output.LayerNorm.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079422134 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.10.output.LayerNorm.weight'. It is no longer used by any node.
2024-08-07 13:45:02.079426137 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.11.intermediate.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079430212 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.9.output.LayerNorm.weight'. It is no longer used by any node.
2024-08-07 13:45:02.079434140 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3727'. It is no longer used by any node.
2024-08-07 13:45:02.079438199 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.17.attention.self.value.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079442145 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3740'. It is no longer used by any node.
2024-08-07 13:45:02.079446345 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.18.attention.self.key.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079450298 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.8.output.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079454184 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.19.output.LayerNorm.weight'. It is no longer used by any node.
2024-08-07 13:45:02.079458141 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.15.output.LayerNorm.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079462224 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.6.attention.output.LayerNorm.weight'. It is no longer used by any node.
2024-08-07 13:45:02.079466189 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.9.attention.output.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079470131 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.6.output.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079474137 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.12.output.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079478185 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.13.attention.self.key.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079482191 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.5.attention.output.LayerNorm.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079486227 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.4.attention.self.key.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079490219 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.8.output.LayerNorm.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079494492 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.8.output.LayerNorm.weight'. It is no longer used by any node.
2024-08-07 13:45:02.079498400 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.12/attention/self/Concat_2_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.079502325 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.9.intermediate.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079506381 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.16.attention.self.value.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079510312 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/Constant_13_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.079514431 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.12.attention.output.LayerNorm.weight'. It is no longer used by any node.
2024-08-07 13:45:02.079518376 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.14.attention.self.value.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079522349 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.7.intermediate.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079526329 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3685'. It is no longer used by any node.
2024-08-07 13:45:02.079530236 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.5.attention.output.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079534256 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.9.output.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079538177 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.12.attention.output.LayerNorm.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079542372 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3634'. It is no longer used by any node.
2024-08-07 13:45:02.079546510 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.1.attention.output.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079550479 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.4.attention.output.LayerNorm.weight'. It is no longer used by any node.
2024-08-07 13:45:02.079554454 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3607'. It is no longer used by any node.
2024-08-07 13:45:02.079558562 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.20.output.LayerNorm.weight'. It is no longer used by any node.
2024-08-07 13:45:02.079562481 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3523'. It is no longer used by any node.
2024-08-07 13:45:02.079566607 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.19.attention.output.LayerNorm.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079570595 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.6.output.LayerNorm.weight'. It is no longer used by any node.
2024-08-07 13:45:02.079574904 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.23.intermediate.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079586867 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.0/attention/self/Concat_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.079591072 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.6.attention.output.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079595029 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.14.output.LayerNorm.weight'. It is no longer used by any node.
2024-08-07 13:45:02.079598977 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3674'. It is no longer used by any node.
2024-08-07 13:45:02.079603240 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.13.intermediate.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079607216 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.9.attention.output.LayerNorm.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079611215 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.15.attention.self.value.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079615077 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.10.attention.self.key.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079619231 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.17.attention.output.LayerNorm.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079624499 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.8.attention.output.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079628568 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3545'. It is no longer used by any node.
2024-08-07 13:45:02.079632530 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.2.attention.output.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079636522 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.20.attention.output.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079640458 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.13.attention.self.value.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079644457 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.1.attention.output.LayerNorm.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079648505 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.10.attention.output.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079652384 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.18.attention.self.query.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079656776 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.14.attention.output.LayerNorm.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079660946 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.4.output.LayerNorm.weight'. It is no longer used by any node.
2024-08-07 13:45:02.079665062 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.embeddings.word_embeddings.weight'. It is no longer used by any node.
2024-08-07 13:45:02.079669007 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.1.output.LayerNorm.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079673063 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.3.attention.output.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079677045 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.2.attention.self.value.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079680942 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3556'. It is no longer used by any node.
2024-08-07 13:45:02.079684896 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3585'. It is no longer used by any node.
2024-08-07 13:45:02.079688851 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3497'. It is no longer used by any node.
2024-08-07 13:45:02.079692768 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.2.output.LayerNorm.weight'. It is no longer used by any node.
2024-08-07 13:45:02.079696659 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.12.attention.self.query.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079700750 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.7.output.LayerNorm.weight'. It is no longer used by any node.
2024-08-07 13:45:02.079704648 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.1.attention.self.value.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079708510 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.1.attention.self.key.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079712783 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.18.intermediate.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079716726 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3744'. It is no longer used by any node.
2024-08-07 13:45:02.079720947 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.6.intermediate.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079724897 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.1.intermediate.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079728818 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.3.attention.output.LayerNorm.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079732726 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.2.intermediate.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079736706 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.2.attention.self.query.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079741228 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.22.attention.output.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079745232 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.5/attention/self/Concat_1_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.079749476 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3598'. It is no longer used by any node.
2024-08-07 13:45:02.079753479 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.9.attention.self.value.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079757393 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.embeddings.LayerNorm.weight'. It is no longer used by any node.
2024-08-07 13:45:02.079761345 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.5.intermediate.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079765642 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.0.attention.self.query.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079769598 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3648'. It is no longer used by any node.
2024-08-07 13:45:02.079773559 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.17.attention.self.key.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079777509 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.7.output.LayerNorm.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079781394 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.1.output.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079785622 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.5/attention/self/Concat_2_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.079789668 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3458'. It is no longer used by any node.
2024-08-07 13:45:02.079793674 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.10.attention.self.value.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079797558 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.16.output.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079801738 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.5.attention.self.value.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079805632 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.2.attention.self.key.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079809910 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.0.intermediate.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079813857 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.17.attention.output.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079817733 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.14.output.LayerNorm.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079821597 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3728'. It is no longer used by any node.
2024-08-07 13:45:02.079825523 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.1.attention.output.LayerNorm.weight'. It is no longer used by any node.
2024-08-07 13:45:02.079829373 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3636'. It is no longer used by any node.
2024-08-07 13:45:02.079833255 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/Mul_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.079837189 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3673'. It is no longer used by any node.
2024-08-07 13:45:02.079841069 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3624'. It is no longer used by any node.
2024-08-07 13:45:02.079844967 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.embeddings.token_type_embeddings.weight'. It is no longer used by any node.
2024-08-07 13:45:02.079849331 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.9/attention/self/Concat_3_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.079853252 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.5.output.LayerNorm.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079857228 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.0.attention.output.LayerNorm.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079861265 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.17/attention/self/Concat_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.079865266 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.16.intermediate.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079869301 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.9.output.LayerNorm.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079873275 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.1.attention.self.query.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079877561 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3506'. It is no longer used by any node.
2024-08-07 13:45:02.079882021 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.0.attention.output.LayerNorm.weight'. It is no longer used by any node.
2024-08-07 13:45:02.079886071 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.19.attention.self.value.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079889972 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.10.attention.output.LayerNorm.weight'. It is no longer used by any node.
2024-08-07 13:45:02.079893953 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3726'. It is no longer used by any node.
2024-08-07 13:45:02.079897805 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3465'. It is no longer used by any node.
2024-08-07 13:45:02.079902002 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.3.output.LayerNorm.weight'. It is no longer used by any node.
2024-08-07 13:45:02.079906005 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.2.attention.output.LayerNorm.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079909979 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.16.output.LayerNorm.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079913861 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3503'. It is no longer used by any node.
2024-08-07 13:45:02.079917721 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.23.attention.output.LayerNorm.weight'. It is no longer used by any node.
2024-08-07 13:45:02.079921668 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3702'. It is no longer used by any node.
2024-08-07 13:45:02.079925715 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.3.output.LayerNorm.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079929653 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3659'. It is no longer used by any node.
2024-08-07 13:45:02.079933628 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.4.attention.self.value.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079937579 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.4.intermediate.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079941545 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3504'. It is no longer used by any node.
2024-08-07 13:45:02.079945421 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.4.attention.output.LayerNorm.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079949367 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.7.attention.self.key.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079953301 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.0.output.LayerNorm.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079957252 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.8.intermediate.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079961438 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.7.attention.output.LayerNorm.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079965480 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3568'. It is no longer used by any node.
2024-08-07 13:45:02.079969416 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.3.output.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079973320 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.13.attention.self.query.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079977319 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.6.attention.self.query.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079981272 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.15.attention.output.LayerNorm.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079985148 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3494'. It is no longer used by any node.
2024-08-07 13:45:02.079989446 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.17.output.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079993378 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.19.output.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.079997422 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.14.attention.output.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080001384 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.7.attention.self.value.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080005285 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3700'. It is no longer used by any node.
2024-08-07 13:45:02.080009180 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.15.output.LayerNorm.weight'. It is no longer used by any node.
2024-08-07 13:45:02.080013058 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3467'. It is no longer used by any node.
2024-08-07 13:45:02.080017398 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3609'. It is no longer used by any node.
2024-08-07 13:45:02.080021445 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.12.output.LayerNorm.weight'. It is no longer used by any node.
2024-08-07 13:45:02.080025578 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.20.output.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080029532 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.13.attention.output.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080033483 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.13.attention.output.LayerNorm.weight'. It is no longer used by any node.
2024-08-07 13:45:02.080037415 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3595'. It is no longer used by any node.
2024-08-07 13:45:02.080041401 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.20.intermediate.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080045215 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.16.output.LayerNorm.weight'. It is no longer used by any node.
2024-08-07 13:45:02.080049145 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.13.output.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080053474 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.13.output.LayerNorm.weight'. It is no longer used by any node.
2024-08-07 13:45:02.080057538 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3662'. It is no longer used by any node.
2024-08-07 13:45:02.080061509 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3752'. It is no longer used by any node.
2024-08-07 13:45:02.080065492 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.21.attention.self.query.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080069399 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.15.attention.self.key.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080073392 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.14.attention.self.key.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080077645 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.14.attention.output.LayerNorm.weight'. It is no longer used by any node.
2024-08-07 13:45:02.080081568 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.22/attention/self/Concat_3_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.080085589 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.13.attention.output.LayerNorm.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080089472 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.14.output.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080093359 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.21.intermediate.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080097312 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.16.attention.self.query.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080101158 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3582'. It is no longer used by any node.
2024-08-07 13:45:02.080105078 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.16/attention/self/Concat_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.080109054 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.4.output.LayerNorm.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080113044 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.3.attention.output.LayerNorm.weight'. It is no longer used by any node.
2024-08-07 13:45:02.080117025 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.18.output.LayerNorm.weight'. It is no longer used by any node.
2024-08-07 13:45:02.080120979 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.15.attention.output.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080124924 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.6.attention.output.LayerNorm.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080128946 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.0.attention.self.key.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080132903 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.15.intermediate.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080136845 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3653'. It is no longer used by any node.
2024-08-07 13:45:02.080141292 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3532'. It is no longer used by any node.
2024-08-07 13:45:02.080145451 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.15.output.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080149435 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.16.attention.output.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080153394 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.4.attention.self.query.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080157271 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.0.output.LayerNorm.weight'. It is no longer used by any node.
2024-08-07 13:45:02.080161167 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.17.attention.self.query.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080165151 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.17.intermediate.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080169148 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.17.output.LayerNorm.weight'. It is no longer used by any node.
2024-08-07 13:45:02.080173134 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.11.attention.output.LayerNorm.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080177100 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.19.attention.output.LayerNorm.weight'. It is no longer used by any node.
2024-08-07 13:45:02.080181103 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3621'. It is no longer used by any node.
2024-08-07 13:45:02.080185066 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.18.attention.output.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080189071 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.8.attention.output.LayerNorm.weight'. It is no longer used by any node.
2024-08-07 13:45:02.080192956 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.22.attention.self.key.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080196844 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.14.intermediate.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080200873 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.18.attention.output.LayerNorm.weight'. It is no longer used by any node.
2024-08-07 13:45:02.080205048 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.10.attention.self.query.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080209057 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.12.output.LayerNorm.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080212890 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.18.output.LayerNorm.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080216809 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.10.output.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080220746 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.19.attention.self.key.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080224767 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.20.attention.self.query.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080228711 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.19.intermediate.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080232666 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.19.output.LayerNorm.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080236821 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3611'. It is no longer used by any node.
2024-08-07 13:45:02.080240998 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.20.attention.self.key.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080244966 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.13.output.LayerNorm.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080248868 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.20.attention.output.LayerNorm.weight'. It is no longer used by any node.
2024-08-07 13:45:02.080252781 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3570'. It is no longer used by any node.
2024-08-07 13:45:02.080256785 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.20.attention.output.LayerNorm.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080260801 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.2/attention/self/Concat_1_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.080264695 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3739'. It is no longer used by any node.
2024-08-07 13:45:02.080268818 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.5.output.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080272741 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.23.output.LayerNorm.weight'. It is no longer used by any node.
2024-08-07 13:45:02.080276855 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Slice_401'. It is no longer used by any node.
2024-08-07 13:45:02.080280774 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.7.attention.self.query.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080284666 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.21.attention.self.key.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080289057 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3479'. It is no longer used by any node.
2024-08-07 13:45:02.080292974 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.16.attention.output.LayerNorm.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080296852 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.21.attention.self.value.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080300924 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.3.intermediate.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080304949 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.21.output.LayerNorm.weight'. It is no longer used by any node.
2024-08-07 13:45:02.080309337 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.21.output.LayerNorm.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080313351 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.0/attention/self/Concat_1_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.080317289 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.22.attention.self.query.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080321257 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.22.output.LayerNorm.weight'. It is no longer used by any node.
2024-08-07 13:45:02.080325237 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.22.attention.output.LayerNorm.weight'. It is no longer used by any node.
2024-08-07 13:45:02.080329257 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3594'. It is no longer used by any node.
2024-08-07 13:45:02.080333171 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/embeddings/Constant_1_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.080337189 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.5.attention.self.key.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080341589 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.22.output.LayerNorm.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080345445 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.23.attention.self.key.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080349380 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.21.attention.output.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080353470 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3558'. It is no longer used by any node.
2024-08-07 13:45:02.080357718 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.11.attention.output.LayerNorm.weight'. It is no longer used by any node.
2024-08-07 13:45:02.080361671 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.23.output.LayerNorm.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080365601 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3442'. It is no longer used by any node.
2024-08-07 13:45:02.080369616 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3445'. It is no longer used by any node.
2024-08-07 13:45:02.080373519 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.embeddings.position_embeddings.weight'. It is no longer used by any node.
2024-08-07 13:45:02.080377402 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3451'. It is no longer used by any node.
2024-08-07 13:45:02.080381330 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3452'. It is no longer used by any node.
2024-08-07 13:45:02.080385325 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3646'. It is no longer used by any node.
2024-08-07 13:45:02.080389297 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.3.attention.self.key.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080393202 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3650'. It is no longer used by any node.
2024-08-07 13:45:02.080397131 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3507'. It is no longer used by any node.
2024-08-07 13:45:02.080401035 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.11.attention.self.key.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080404904 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3663'. It is no longer used by any node.
2024-08-07 13:45:02.080409000 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.19.attention.self.query.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080412870 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.22.output.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080416754 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3588'. It is no longer used by any node.
2024-08-07 13:45:02.080420784 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.23.attention.output.LayerNorm.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080424624 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.6.attention.self.value.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080428426 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.3.attention.self.value.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080432199 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.21.attention.output.LayerNorm.weight'. It is no longer used by any node.
2024-08-07 13:45:02.080436398 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3454'. It is no longer used by any node.
2024-08-07 13:45:02.080440387 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3481'. It is no longer used by any node.
2024-08-07 13:45:02.080444359 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.10.output.LayerNorm.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080448245 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.16.attention.self.key.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080452240 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.22.attention.output.LayerNorm.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080456106 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.6/attention/self/Concat_2_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.080460028 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.11.output.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080463951 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.17.attention.output.LayerNorm.weight'. It is no longer used by any node.
2024-08-07 13:45:02.080467882 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3466'. It is no longer used by any node.
2024-08-07 13:45:02.080471880 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.9.attention.output.LayerNorm.weight'. It is no longer used by any node.
2024-08-07 13:45:02.080475824 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.1.output.LayerNorm.weight'. It is no longer used by any node.
2024-08-07 13:45:02.080479729 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.22.attention.self.value.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080483544 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3661'. It is no longer used by any node.
2024-08-07 13:45:02.080487557 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.5.attention.output.LayerNorm.weight'. It is no longer used by any node.
2024-08-07 13:45:02.080491445 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.11.attention.output.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080495380 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.8.attention.self.value.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080499317 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.16.attention.output.LayerNorm.weight'. It is no longer used by any node.
2024-08-07 13:45:02.080503272 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3517'. It is no longer used by any node.
2024-08-07 13:45:02.080507230 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.2.attention.output.LayerNorm.weight'. It is no longer used by any node.
2024-08-07 13:45:02.080511332 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.2.output.LayerNorm.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080515484 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/2/Constant_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.080519441 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.21.output.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080523409 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.4/attention/self/Concat_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.080527710 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.0.output.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080531637 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3492'. It is no longer used by any node.
2024-08-07 13:45:02.080535804 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3679'. It is no longer used by any node.
2024-08-07 13:45:02.080539672 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3698'. It is no longer used by any node.
2024-08-07 13:45:02.080543757 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.0.attention.self.value.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080547647 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.19.attention.output.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080551550 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.20.attention.self.value.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080555536 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.7.attention.output.LayerNorm.weight'. It is no longer used by any node.
2024-08-07 13:45:02.080559477 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3575'. It is no longer used by any node.
2024-08-07 13:45:02.080563402 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3491'. It is no longer used by any node.
2024-08-07 13:45:02.080567380 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3484'. It is no longer used by any node.
2024-08-07 13:45:02.080571194 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3675'. It is no longer used by any node.
2024-08-07 13:45:02.080575270 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.embeddings.LayerNorm.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080579459 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3713'. It is no longer used by any node.
2024-08-07 13:45:02.080583469 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3614'. It is no longer used by any node.
2024-08-07 13:45:02.080587709 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.15.attention.self.query.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080591694 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3569'. It is no longer used by any node.
2024-08-07 13:45:02.080595565 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.23.output.dense.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080599427 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '/0/auto_model/encoder/layer.9/attention/self/Concat_1_output_0'. It is no longer used by any node.
2024-08-07 13:45:02.080603555 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.8.attention.self.query.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080607637 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3676'. It is no longer used by any node.
2024-08-07 13:45:02.080611768 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.23.attention.self.query.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080615717 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer '0.auto_model.encoder.layer.5.attention.self.query.bias'. It is no longer used by any node.
2024-08-07 13:45:02.080620060 [I:onnxruntime:, graph.cc:4096 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::MatMul_3672'. It is no longer used by any node.
2024-08-07 13:45:02.081458964 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer TransposeOptimizer_CPUExecutionProvider modified: 0 with status: OK
2024-08-07 13:45:02.081475625 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer QDQS8ToU8Transformer modified: 0 with status: OK
2024-08-07 13:45:02.081485890 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer QDQSelectorActionTransformer modified: 0 with status: OK
2024-08-07 13:45:02.081496087 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer GemmActivationFusion modified: 0 with status: OK
2024-08-07 13:45:02.081504703 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer MatMulIntegerToFloatFusion modified: 0 with status: OK
2024-08-07 13:45:02.081513641 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer DynamicQuantizeMatMulFusion modified: 0 with status: OK
2024-08-07 13:45:02.081523138 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer ConvActivationFusion modified: 0 with status: OK
2024-08-07 13:45:02.081531745 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer GeluFusion modified: 0 with status: OK
2024-08-07 13:45:02.081540151 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer LayerNormFusion modified: 0 with status: OK
2024-08-07 13:45:02.081548101 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer SimplifiedLayerNormFusion modified: 0 with status: OK
2024-08-07 13:45:02.081561172 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer AttentionFusion modified: 0 with status: OK
2024-08-07 13:45:02.081569819 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer EmbedLayerNormFusion modified: 0 with status: OK
2024-08-07 13:45:02.081578783 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer GatherSliceToSplitFusion modified: 0 with status: OK
2024-08-07 13:45:02.081587233 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer GatherToSliceFusion modified: 0 with status: OK
2024-08-07 13:45:02.081596007 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer MatmulTransposeFusion modified: 0 with status: OK
2024-08-07 13:45:02.081604222 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer BiasGeluFusion modified: 0 with status: OK
2024-08-07 13:45:02.081612622 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer SkipLayerNormFusion modified: 1 with status: OK
2024-08-07 13:45:02.081623457 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer FastGeluFusion modified: 0 with status: OK
2024-08-07 13:45:02.081631653 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer QuickGeluFusion modified: 0 with status: OK
2024-08-07 13:45:02.081640140 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer BiasSoftmaxFusion modified: 0 with status: OK
2024-08-07 13:45:02.081648068 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer BiasDropoutFusion modified: 0 with status: OK
2024-08-07 13:45:02.081656176 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer MatMulScaleFusion modified: 0 with status: OK
2024-08-07 13:45:02.081664002 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer MatMulActivationFusion modified: 0 with status: OK
2024-08-07 13:45:02.081672465 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer QDQFinalCleanupTransformer modified: 0 with status: OK
2024-08-07 13:45:02.081680157 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer QDQS8ToU8Transformer modified: 0 with status: OK
2024-08-07 13:45:02.081687747 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer QDQSelectorActionTransformer modified: 0 with status: OK
2024-08-07 13:45:02.081695386 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer GemmActivationFusion modified: 0 with status: OK
2024-08-07 13:45:02.081702986 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer MatMulIntegerToFloatFusion modified: 0 with status: OK
2024-08-07 13:45:02.081710610 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer DynamicQuantizeMatMulFusion modified: 0 with status: OK
2024-08-07 13:45:02.081718097 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer ConvActivationFusion modified: 0 with status: OK
2024-08-07 13:45:02.081725657 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer GeluFusion modified: 0 with status: OK
2024-08-07 13:45:02.081733296 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer LayerNormFusion modified: 0 with status: OK
2024-08-07 13:45:02.081741031 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer SimplifiedLayerNormFusion modified: 0 with status: OK
2024-08-07 13:45:02.081748762 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer AttentionFusion modified: 0 with status: OK
2024-08-07 13:45:02.081756446 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer EmbedLayerNormFusion modified: 0 with status: OK
2024-08-07 13:45:02.081766168 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer GatherSliceToSplitFusion modified: 0 with status: OK
2024-08-07 13:45:02.081773927 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer GatherToSliceFusion modified: 0 with status: OK
2024-08-07 13:45:02.081782082 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer MatmulTransposeFusion modified: 0 with status: OK
2024-08-07 13:45:02.081789634 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer BiasGeluFusion modified: 0 with status: OK
2024-08-07 13:45:02.081797270 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer SkipLayerNormFusion modified: 1 with status: OK
2024-08-07 13:45:02.081806618 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer FastGeluFusion modified: 0 with status: OK
2024-08-07 13:45:02.081815761 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer QuickGeluFusion modified: 0 with status: OK
2024-08-07 13:45:02.081823343 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer BiasSoftmaxFusion modified: 0 with status: OK
2024-08-07 13:45:02.081830864 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer BiasDropoutFusion modified: 0 with status: OK
2024-08-07 13:45:02.081838395 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer MatMulScaleFusion modified: 0 with status: OK
2024-08-07 13:45:02.081845934 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer MatMulActivationFusion modified: 0 with status: OK
2024-08-07 13:45:02.081853515 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer QDQFinalCleanupTransformer modified: 0 with status: OK
2024-08-07 13:45:02.081861134 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer QDQS8ToU8Transformer modified: 0 with status: OK
2024-08-07 13:45:02.081868676 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer QDQSelectorActionTransformer modified: 0 with status: OK
2024-08-07 13:45:02.081876206 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer GemmActivationFusion modified: 0 with status: OK
2024-08-07 13:45:02.081883697 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer MatMulIntegerToFloatFusion modified: 0 with status: OK
2024-08-07 13:45:02.081891281 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer DynamicQuantizeMatMulFusion modified: 0 with status: OK
2024-08-07 13:45:02.081898729 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer ConvActivationFusion modified: 0 with status: OK
2024-08-07 13:45:02.081906231 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer GeluFusion modified: 0 with status: OK
2024-08-07 13:45:02.081913744 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer LayerNormFusion modified: 0 with status: OK
2024-08-07 13:45:02.081922968 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer SimplifiedLayerNormFusion modified: 0 with status: OK
2024-08-07 13:45:02.081930557 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer AttentionFusion modified: 0 with status: OK
2024-08-07 13:45:02.081938077 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer EmbedLayerNormFusion modified: 0 with status: OK
2024-08-07 13:45:02.081945811 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer GatherSliceToSplitFusion modified: 0 with status: OK
2024-08-07 13:45:02.081954396 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer GatherToSliceFusion modified: 0 with status: OK
2024-08-07 13:45:02.081962069 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer MatmulTransposeFusion modified: 0 with status: OK
2024-08-07 13:45:02.081969581 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer BiasGeluFusion modified: 0 with status: OK
2024-08-07 13:45:02.081977113 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer SkipLayerNormFusion modified: 1 with status: OK
2024-08-07 13:45:02.081986207 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer FastGeluFusion modified: 0 with status: OK
2024-08-07 13:45:02.081993728 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer QuickGeluFusion modified: 0 with status: OK
2024-08-07 13:45:02.082001233 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer BiasSoftmaxFusion modified: 0 with status: OK
2024-08-07 13:45:02.082008754 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer BiasDropoutFusion modified: 0 with status: OK
2024-08-07 13:45:02.082016302 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer MatMulScaleFusion modified: 0 with status: OK
2024-08-07 13:45:02.082023802 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer MatMulActivationFusion modified: 0 with status: OK
2024-08-07 13:45:02.082031377 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer QDQFinalCleanupTransformer modified: 0 with status: OK
2024-08-07 13:45:02.082038955 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer QDQS8ToU8Transformer modified: 0 with status: OK
2024-08-07 13:45:02.082046656 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer QDQSelectorActionTransformer modified: 0 with status: OK
2024-08-07 13:45:02.082054187 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer GemmActivationFusion modified: 0 with status: OK
2024-08-07 13:45:02.082061790 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer MatMulIntegerToFloatFusion modified: 0 with status: OK
2024-08-07 13:45:02.082069254 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer DynamicQuantizeMatMulFusion modified: 0 with status: OK
2024-08-07 13:45:02.082076801 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer ConvActivationFusion modified: 0 with status: OK
2024-08-07 13:45:02.082084288 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer GeluFusion modified: 0 with status: OK
2024-08-07 13:45:02.082091864 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer LayerNormFusion modified: 0 with status: OK
2024-08-07 13:45:02.082099447 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer SimplifiedLayerNormFusion modified: 0 with status: OK
2024-08-07 13:45:02.082107753 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer AttentionFusion modified: 0 with status: OK
2024-08-07 13:45:02.082115402 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer EmbedLayerNormFusion modified: 0 with status: OK
2024-08-07 13:45:02.082123066 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer GatherSliceToSplitFusion modified: 0 with status: OK
2024-08-07 13:45:02.082130735 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer GatherToSliceFusion modified: 0 with status: OK
2024-08-07 13:45:02.082138374 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer MatmulTransposeFusion modified: 0 with status: OK
2024-08-07 13:45:02.082145881 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer BiasGeluFusion modified: 0 with status: OK
2024-08-07 13:45:02.082153553 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer SkipLayerNormFusion modified: 1 with status: OK
2024-08-07 13:45:02.082162583 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer FastGeluFusion modified: 0 with status: OK
2024-08-07 13:45:02.082170095 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer QuickGeluFusion modified: 0 with status: OK
2024-08-07 13:45:02.082177556 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer BiasSoftmaxFusion modified: 0 with status: OK
2024-08-07 13:45:02.082185118 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer BiasDropoutFusion modified: 0 with status: OK
2024-08-07 13:45:02.082192693 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer MatMulScaleFusion modified: 0 with status: OK
2024-08-07 13:45:02.082200191 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer MatMulActivationFusion modified: 0 with status: OK
2024-08-07 13:45:02.082207762 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer QDQFinalCleanupTransformer modified: 0 with status: OK
2024-08-07 13:45:02.082215270 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer QDQS8ToU8Transformer modified: 0 with status: OK
2024-08-07 13:45:02.082222824 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer QDQSelectorActionTransformer modified: 0 with status: OK
2024-08-07 13:45:02.082230489 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer GemmActivationFusion modified: 0 with status: OK
2024-08-07 13:45:02.082238570 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer MatMulIntegerToFloatFusion modified: 0 with status: OK
2024-08-07 13:45:02.082246119 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer DynamicQuantizeMatMulFusion modified: 0 with status: OK
2024-08-07 13:45:02.082253591 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer ConvActivationFusion modified: 0 with status: OK
2024-08-07 13:45:02.082261033 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer GeluFusion modified: 0 with status: OK
2024-08-07 13:45:02.082268530 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer LayerNormFusion modified: 0 with status: OK
2024-08-07 13:45:02.082275987 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer SimplifiedLayerNormFusion modified: 0 with status: OK
2024-08-07 13:45:02.082283509 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer AttentionFusion modified: 0 with status: OK
2024-08-07 13:45:02.082290970 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer EmbedLayerNormFusion modified: 0 with status: OK
2024-08-07 13:45:02.082298610 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer GatherSliceToSplitFusion modified: 0 with status: OK
2024-08-07 13:45:02.082306103 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer GatherToSliceFusion modified: 0 with status: OK
2024-08-07 13:45:02.082313687 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer MatmulTransposeFusion modified: 0 with status: OK
2024-08-07 13:45:02.082321162 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer BiasGeluFusion modified: 0 with status: OK
2024-08-07 13:45:02.082328689 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer SkipLayerNormFusion modified: 1 with status: OK
2024-08-07 13:45:02.082338582 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer FastGeluFusion modified: 0 with status: OK
2024-08-07 13:45:02.082346227 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer QuickGeluFusion modified: 0 with status: OK
2024-08-07 13:45:02.082353719 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer BiasSoftmaxFusion modified: 0 with status: OK
2024-08-07 13:45:02.082361156 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer BiasDropoutFusion modified: 0 with status: OK
2024-08-07 13:45:02.082368673 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer MatMulScaleFusion modified: 0 with status: OK
2024-08-07 13:45:02.082376097 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer MatMulActivationFusion modified: 0 with status: OK
2024-08-07 13:45:02.082383577 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer QDQFinalCleanupTransformer modified: 0 with status: OK
2024-08-07 13:45:02.082391056 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer QDQS8ToU8Transformer modified: 0 with status: OK
2024-08-07 13:45:02.082398523 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer QDQSelectorActionTransformer modified: 0 with status: OK
2024-08-07 13:45:02.082406071 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer GemmActivationFusion modified: 0 with status: OK
2024-08-07 13:45:02.082413653 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer MatMulIntegerToFloatFusion modified: 0 with status: OK
2024-08-07 13:45:02.082421108 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer DynamicQuantizeMatMulFusion modified: 0 with status: OK
2024-08-07 13:45:02.082428523 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer ConvActivationFusion modified: 0 with status: OK
2024-08-07 13:45:02.082436033 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer GeluFusion modified: 0 with status: OK
2024-08-07 13:45:02.082443523 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer LayerNormFusion modified: 0 with status: OK
2024-08-07 13:45:02.082450996 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer SimplifiedLayerNormFusion modified: 0 with status: OK
2024-08-07 13:45:02.082458559 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer AttentionFusion modified: 0 with status: OK
2024-08-07 13:45:02.082466004 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer EmbedLayerNormFusion modified: 0 with status: OK
2024-08-07 13:45:02.082473683 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer GatherSliceToSplitFusion modified: 0 with status: OK
2024-08-07 13:45:02.082481174 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer GatherToSliceFusion modified: 0 with status: OK
2024-08-07 13:45:02.082488759 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer MatmulTransposeFusion modified: 0 with status: OK
2024-08-07 13:45:02.082496210 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer BiasGeluFusion modified: 0 with status: OK
2024-08-07 13:45:02.082503763 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer SkipLayerNormFusion modified: 1 with status: OK
2024-08-07 13:45:02.082512793 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer FastGeluFusion modified: 0 with status: OK
2024-08-07 13:45:02.082520266 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer QuickGeluFusion modified: 0 with status: OK
2024-08-07 13:45:02.082527773 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer BiasSoftmaxFusion modified: 0 with status: OK
2024-08-07 13:45:02.082535290 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer BiasDropoutFusion modified: 0 with status: OK
2024-08-07 13:45:02.082542737 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer MatMulScaleFusion modified: 0 with status: OK
2024-08-07 13:45:02.082550266 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer MatMulActivationFusion modified: 0 with status: OK
2024-08-07 13:45:02.082557888 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer QDQFinalCleanupTransformer modified: 0 with status: OK
2024-08-07 13:45:02.082565332 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer QDQS8ToU8Transformer modified: 0 with status: OK
2024-08-07 13:45:02.082572830 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer QDQSelectorActionTransformer modified: 0 with status: OK
2024-08-07 13:45:02.082580364 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer GemmActivationFusion modified: 0 with status: OK
2024-08-07 13:45:02.082587836 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer MatMulIntegerToFloatFusion modified: 0 with status: OK
2024-08-07 13:45:02.082595447 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer DynamicQuantizeMatMulFusion modified: 0 with status: OK
2024-08-07 13:45:02.082602853 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer ConvActivationFusion modified: 0 with status: OK
2024-08-07 13:45:02.082610366 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer GeluFusion modified: 0 with status: OK
2024-08-07 13:45:02.082617871 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer LayerNormFusion modified: 0 with status: OK
2024-08-07 13:45:02.082625385 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer SimplifiedLayerNormFusion modified: 0 with status: OK
2024-08-07 13:45:02.082632912 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer AttentionFusion modified: 0 with status: OK
2024-08-07 13:45:02.082640443 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer EmbedLayerNormFusion modified: 0 with status: OK
2024-08-07 13:45:02.082648270 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer GatherSliceToSplitFusion modified: 0 with status: OK
2024-08-07 13:45:02.082655767 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer GatherToSliceFusion modified: 0 with status: OK
2024-08-07 13:45:02.082663622 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer MatmulTransposeFusion modified: 0 with status: OK
2024-08-07 13:45:02.082671147 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer BiasGeluFusion modified: 0 with status: OK
2024-08-07 13:45:02.082678621 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer SkipLayerNormFusion modified: 1 with status: OK
2024-08-07 13:45:02.082687820 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer FastGeluFusion modified: 0 with status: OK
2024-08-07 13:45:02.082695809 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer QuickGeluFusion modified: 0 with status: OK
2024-08-07 13:45:02.082703465 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer BiasSoftmaxFusion modified: 0 with status: OK
2024-08-07 13:45:02.082711735 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer BiasDropoutFusion modified: 0 with status: OK
2024-08-07 13:45:02.082719299 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer MatMulScaleFusion modified: 0 with status: OK
2024-08-07 13:45:02.082728167 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer MatMulActivationFusion modified: 0 with status: OK
2024-08-07 13:45:02.082735832 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer QDQFinalCleanupTransformer modified: 0 with status: OK
2024-08-07 13:45:02.082743308 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer QDQS8ToU8Transformer modified: 0 with status: OK
2024-08-07 13:45:02.082750792 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer QDQSelectorActionTransformer modified: 0 with status: OK
2024-08-07 13:45:02.082758306 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer GemmActivationFusion modified: 0 with status: OK
2024-08-07 13:45:02.082765843 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer MatMulIntegerToFloatFusion modified: 0 with status: OK
2024-08-07 13:45:02.082773371 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer DynamicQuantizeMatMulFusion modified: 0 with status: OK
2024-08-07 13:45:02.082780885 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer ConvActivationFusion modified: 0 with status: OK
2024-08-07 13:45:02.082788380 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer GeluFusion modified: 0 with status: OK
2024-08-07 13:45:02.082795915 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer LayerNormFusion modified: 0 with status: OK
2024-08-07 13:45:02.082803705 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer SimplifiedLayerNormFusion modified: 0 with status: OK
2024-08-07 13:45:02.082814107 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer AttentionFusion modified: 0 with status: OK
2024-08-07 13:45:02.082821780 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer EmbedLayerNormFusion modified: 0 with status: OK
2024-08-07 13:45:02.082830729 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer GatherSliceToSplitFusion modified: 0 with status: OK
2024-08-07 13:45:02.082838435 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer GatherToSliceFusion modified: 0 with status: OK
2024-08-07 13:45:02.082846046 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer MatmulTransposeFusion modified: 0 with status: OK
2024-08-07 13:45:02.082853592 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer BiasGeluFusion modified: 0 with status: OK
2024-08-07 13:45:02.082861172 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer SkipLayerNormFusion modified: 1 with status: OK
2024-08-07 13:45:02.082870986 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer FastGeluFusion modified: 0 with status: OK
2024-08-07 13:45:02.082878622 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer QuickGeluFusion modified: 0 with status: OK
2024-08-07 13:45:02.082886128 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer BiasSoftmaxFusion modified: 0 with status: OK
2024-08-07 13:45:02.082893657 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer BiasDropoutFusion modified: 0 with status: OK
2024-08-07 13:45:02.082901237 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer MatMulScaleFusion modified: 0 with status: OK
2024-08-07 13:45:02.082908727 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer MatMulActivationFusion modified: 0 with status: OK
2024-08-07 13:45:02.082916310 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer QDQFinalCleanupTransformer modified: 0 with status: OK
2024-08-07 13:45:02.082923862 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer QDQS8ToU8Transformer modified: 0 with status: OK
2024-08-07 13:45:02.082931375 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer QDQSelectorActionTransformer modified: 0 with status: OK
2024-08-07 13:45:02.082938920 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer GemmActivationFusion modified: 0 with status: OK
2024-08-07 13:45:02.082946403 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer MatMulIntegerToFloatFusion modified: 0 with status: OK
2024-08-07 13:45:02.082954047 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer DynamicQuantizeMatMulFusion modified: 0 with status: OK
2024-08-07 13:45:02.082961482 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer ConvActivationFusion modified: 0 with status: OK
2024-08-07 13:45:02.082969072 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer GeluFusion modified: 0 with status: OK
2024-08-07 13:45:02.082976540 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer LayerNormFusion modified: 0 with status: OK
2024-08-07 13:45:02.082984066 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer SimplifiedLayerNormFusion modified: 0 with status: OK
2024-08-07 13:45:02.082991572 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer AttentionFusion modified: 0 with status: OK
2024-08-07 13:45:02.082999318 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer EmbedLayerNormFusion modified: 0 with status: OK
2024-08-07 13:45:02.083007001 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer GatherSliceToSplitFusion modified: 0 with status: OK
2024-08-07 13:45:02.083014499 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer GatherToSliceFusion modified: 0 with status: OK
2024-08-07 13:45:02.083022113 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer MatmulTransposeFusion modified: 0 with status: OK
2024-08-07 13:45:02.083029578 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer BiasGeluFusion modified: 0 with status: OK
2024-08-07 13:45:02.083037142 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer SkipLayerNormFusion modified: 1 with status: OK
2024-08-07 13:45:02.083046169 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer FastGeluFusion modified: 0 with status: OK
2024-08-07 13:45:02.083053706 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer QuickGeluFusion modified: 0 with status: OK
2024-08-07 13:45:02.083061217 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer BiasSoftmaxFusion modified: 0 with status: OK
2024-08-07 13:45:02.083068882 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer BiasDropoutFusion modified: 0 with status: OK
2024-08-07 13:45:02.083076425 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer MatMulScaleFusion modified: 0 with status: OK
2024-08-07 13:45:02.083083904 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer MatMulActivationFusion modified: 0 with status: OK
2024-08-07 13:45:02.083091475 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer QDQFinalCleanupTransformer modified: 0 with status: OK
2024-08-07 13:45:02.083099002 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer QDQS8ToU8Transformer modified: 0 with status: OK
2024-08-07 13:45:02.083106688 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer QDQSelectorActionTransformer modified: 0 with status: OK
2024-08-07 13:45:02.083114230 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer GemmActivationFusion modified: 0 with status: OK
2024-08-07 13:45:02.083121780 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer MatMulIntegerToFloatFusion modified: 0 with status: OK
2024-08-07 13:45:02.083129476 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer DynamicQuantizeMatMulFusion modified: 0 with status: OK
2024-08-07 13:45:02.083136975 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer ConvActivationFusion modified: 0 with status: OK
2024-08-07 13:45:02.083146144 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer GeluFusion modified: 0 with status: OK
2024-08-07 13:45:02.083153742 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer LayerNormFusion modified: 0 with status: OK
2024-08-07 13:45:02.083161981 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer SimplifiedLayerNormFusion modified: 0 with status: OK
2024-08-07 13:45:02.083169671 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer AttentionFusion modified: 0 with status: OK
2024-08-07 13:45:02.083177793 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer EmbedLayerNormFusion modified: 0 with status: OK
2024-08-07 13:45:02.083185555 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer GatherSliceToSplitFusion modified: 0 with status: OK
2024-08-07 13:45:02.083193074 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer GatherToSliceFusion modified: 0 with status: OK
2024-08-07 13:45:02.083200631 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer MatmulTransposeFusion modified: 0 with status: OK
2024-08-07 13:45:02.083208194 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer BiasGeluFusion modified: 0 with status: OK
2024-08-07 13:45:02.083215841 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer SkipLayerNormFusion modified: 1 with status: OK
2024-08-07 13:45:02.083224888 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer FastGeluFusion modified: 0 with status: OK
2024-08-07 13:45:02.083232380 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer QuickGeluFusion modified: 0 with status: OK
2024-08-07 13:45:02.083239862 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer BiasSoftmaxFusion modified: 0 with status: OK
2024-08-07 13:45:02.083247364 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer BiasDropoutFusion modified: 0 with status: OK
2024-08-07 13:45:02.083254931 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer MatMulScaleFusion modified: 0 with status: OK
2024-08-07 13:45:02.083262384 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer MatMulActivationFusion modified: 0 with status: OK
2024-08-07 13:45:02.083269929 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer QDQFinalCleanupTransformer modified: 0 with status: OK
2024-08-07 13:45:02.083278733 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer NchwcTransformer modified: 0 with status: OK
2024-08-07 13:45:02.083291931 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer NhwcTransformer modified: 0 with status: OK
2024-08-07 13:45:02.083300871 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer ConvAddActivationFusion modified: 0 with status: OK
2024-08-07 13:45:02.083314699 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer RemoveDuplicateCastTransformer modified: 0 with status: OK
2024-08-07 13:45:02.083320102 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer CastFloat16Transformer modified: 0 with status: OK
2024-08-07 13:45:02.083341054 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer MemcpyTransformer modified: 0 with status: OK
2024-08-07 13:45:02.083364706 [V:onnxruntime:, session_state.cc:1146 VerifyEachNodeIsAssignedToAnEp] Node placements
2024-08-07 13:45:02.083370266 [V:onnxruntime:, session_state.cc:1149 VerifyEachNodeIsAssignedToAnEp]  All nodes placed on [TensorrtExecutionProvider]. Number of nodes: 1
2024-08-07 13:45:02.083384386 [V:onnxruntime:, session_state.cc:126 CreateGraphInfo] SaveMLValueNameIndexMapping
2024-08-07 13:45:02.083393549 [V:onnxruntime:, session_state.cc:172 CreateGraphInfo] Done saving OrtValue mappings.
2024-08-07 13:45:02.104517993 [I:onnxruntime:, allocation_planner.cc:2442 CreateGraphPartitioner] Use DeviceBasedPartition as default
2024-08-07 13:45:02.104576086 [I:onnxruntime:, session_state_utils.cc:201 SaveInitializedTensors] Saving initialized tensors.
2024-08-07 13:45:02.104584615 [I:onnxruntime:, session_state_utils.cc:345 SaveInitializedTensors] Done saving initialized tensors
2024-08-07 13:45:02.104627537 [I:onnxruntime:, inference_session.cc:2033 Initialize] Session successfully initialized.
I0807 13:45:02.104689 28 backend_model_instance.cc:362] "Generating warmup sample data for 'onnx_ort_warmup_min'"
I0807 13:45:02.104793 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.104802 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63fc6f9190] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aab4004c8] input: input_ids, type: INT64, original shape: [1,4], batch + shape: [1,4], shape: [4]\n[0x0x7f6aab4003c8] input: attention_mask, type: INT64, original shape: [1,4], batch + shape: [1,4], shape: [4]\noverride inputs:\ninputs:\n[0x0x7f6aab4003c8] input: attention_mask, type: INT64, original shape: [1,4], batch + shape: [1,4], shape: [4]\n[0x0x7f6aab4004c8] input: input_ids, type: INT64, original shape: [1,4], batch + shape: [1,4], shape: [4]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.104819 28 backend_model_instance.cc:362] "Generating warmup sample data for 'onnx_ort_warmup_max'"
I0807 13:45:02.105478 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.105488 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebc3e4f0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aab400ea8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aab4006b8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aab4006b8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aab400ea8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.106127 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.106136 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebc3f0e0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebc3f838] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebc3ecd8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebc3ecd8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebc3f838] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.106630 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.106639 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebc3fc20] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebc403c8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebc3fb48] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebc3fb48] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebc403c8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.107086 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.107095 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6474640] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6474c28] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebc406d8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebc406d8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6474c28] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.107542 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.107551 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6474fc0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa64756e8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6474ee8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6474ee8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa64756e8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.108032 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.108042 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6475ad0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6476228] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa64759f8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa64759f8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6476228] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.108479 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.108488 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aaa200080] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aaa2007d8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6476538] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6476538] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa2007d8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.108925 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.108934 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aaa200c60] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aaa2013b8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa200b88] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aaa200b88] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa2013b8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.109366 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.109375 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aaa201840] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aaa201f48] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa201768] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aaa201768] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa201f48] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.109820 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.109830 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aaa2023d0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aaa202b28] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa2022f8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aaa2022f8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa202b28] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.110272 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.110280 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aaa202fb0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aaa203708] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa202ed8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aaa202ed8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa203708] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.110709 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.110718 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aaa203b90] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aaa2042e8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa203ab8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aaa203ab8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa2042e8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.111151 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.111160 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aaa204770] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aaa204ec8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa204698] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aaa204698] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa204ec8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.111603 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.111612 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aaa205350] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aaa205aa8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa205278] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aaa205278] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa205aa8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.112037 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.112046 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aaa205f30] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aaa206688] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa205e58] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aaa205e58] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa206688] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.112472 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.112481 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aaa206b10] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aaa207268] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa206a38] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aaa206a38] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa207268] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.112891 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.112900 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aaa2076f0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aaa207e48] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa207618] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aaa207618] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa207e48] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.113317 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.113325 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aaa2082d0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aaa208a28] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa2081f8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aaa2081f8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa208a28] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.113745 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.113754 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aaa208eb0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aaa209608] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa208dd8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aaa208dd8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa209608] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.114171 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.114180 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aaa209a90] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aaa20a1e8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa2099b8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aaa2099b8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa20a1e8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.114603 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.114612 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aaa20a670] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aaa20adc8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa20a598] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aaa20a598] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa20adc8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.115039 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.115048 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aaa20b250] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aaa20b9a8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa20b178] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aaa20b178] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa20b9a8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.115474 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.115483 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aaa20be30] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aaa20c588] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa20bd58] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aaa20bd58] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa20c588] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.115920 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.115930 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aaa20ca10] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aaa20d168] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa20c938] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aaa20c938] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa20d168] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.116360 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.116369 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aaa20d5f0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aaa20dd48] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa20d518] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aaa20d518] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa20dd48] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.116804 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.116813 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aaa20e1d0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aaa20e928] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa20e0f8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aaa20e0f8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa20e928] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.117252 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.117260 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aaa20edb0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aaa20f508] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa20ecd8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aaa20ecd8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa20f508] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.117679 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.117687 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aaa20f990] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aaa2100e8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa20f8b8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aaa20f8b8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa2100e8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.118102 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.118110 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aaa210570] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aaa210cc8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa210498] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aaa210498] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa210cc8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.118523 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.118532 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aaa211150] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aaa2118a8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa211078] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aaa211078] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa2118a8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.118952 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.118961 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aaa211d30] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aaa212488] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa211c58] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aaa211c58] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa212488] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.119379 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.119388 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aaa212910] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aaa213068] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa212838] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aaa212838] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa213068] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.119826 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.119835 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aaa2134f0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aaa213c48] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa213418] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aaa213418] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa213c48] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.120250 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.120259 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aaa2140d0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aaa214828] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa213ff8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aaa213ff8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa214828] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.120679 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.120687 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aaa214cb0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ef600268] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa214bd8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aaa214bd8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ef600268] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.121126 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.121135 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ef6006f0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ef600e48] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ef600618] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ef600618] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ef600e48] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.121552 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.121561 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ef6012d0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ef601a28] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ef6011f8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ef6011f8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ef601a28] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.121988 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.121997 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ef601eb0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ef602608] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ef601dd8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ef601dd8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ef602608] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.122435 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.122444 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ef602a90] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aaa215488] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ef6029b8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ef6029b8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa215488] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.122877 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.122886 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aaa215910] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aaa216068] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa215838] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aaa215838] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa216068] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.123322 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.123331 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aaa2164f0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aaa216c48] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa216418] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aaa216418] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa216c48] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.123834 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.123845 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aaa2170d0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aaa217828] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa216ff8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aaa216ff8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa217828] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.124271 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.124280 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aaa217cb0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aaa218408] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa217bd8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aaa217bd8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa218408] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.124689 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.124697 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aaa218890] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aaa218fe8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa2187b8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aaa2187b8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa218fe8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.125117 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.125126 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aaa219470] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aaa219bc8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa219398] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aaa219398] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa219bc8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.126369 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.126380 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aaa21a050] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aaa21a7a8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa219f78] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aaa219f78] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa21a7a8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.127609 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.127619 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aaa21ac30] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aaa21b388] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa21ab58] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aaa21ab58] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa21b388] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.128838 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.128848 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa62000b0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6200808] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aaa21b738] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aaa21b738] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6200808] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.130057 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.130067 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6200c90] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa62013e8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6200bb8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6200bb8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa62013e8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.131283 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.131292 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa62018b0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6202068] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa62017d8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa62017d8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6202068] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.132511 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.132521 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa62025d0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6202d88] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa62024f8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa62024f8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6202d88] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.133739 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.133749 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa62032f0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6203aa8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6203218] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6203218] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6203aa8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.134959 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.134969 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6204010] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa62047c8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6203f38] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6203f38] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa62047c8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.136226 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.136236 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6204d30] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa62054e8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6204c58] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6204c58] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa62054e8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.137481 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.137490 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6205a50] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6206208] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6205978] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6205978] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6206208] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.138749 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.138759 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6206770] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6206f28] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6206698] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6206698] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6206f28] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.140023 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.140033 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6207490] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6207c48] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa62073b8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa62073b8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6207c48] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.141289 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.141298 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa62081b0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6208968] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa62080d8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa62080d8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6208968] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.142554 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.142563 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6208ed0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6209688] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6208df8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6208df8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6209688] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.143862 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.143873 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6209bf0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa620a3a8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6209b18] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6209b18] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa620a3a8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.145120 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.145130 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa620a910] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa620b0c8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa620a838] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa620a838] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa620b0c8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.146385 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.146394 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa620b630] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa620bde8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa620b558] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa620b558] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa620bde8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.147655 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.147664 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa620c350] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa620cb08] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa620c278] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa620c278] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa620cb08] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.148921 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.148931 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa620d070] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa620d828] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa620cf98] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa620cf98] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa620d828] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.150173 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.150183 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa620dd90] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa620eba8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa620dcb8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa620dcb8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa620eba8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.151438 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.151447 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa620f110] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa620f8c8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa620f038] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa620f038] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa620f8c8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.152712 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.152722 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa620fe30] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa62105e8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa620fd58] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa620fd58] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa62105e8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.153971 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.153981 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6210b50] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6211308] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6210a78] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6210a78] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6211308] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.155241 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.155251 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6211870] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6212028] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6211798] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6211798] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6212028] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.156560 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.156571 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6212590] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6212d48] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa62124b8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa62124b8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6212d48] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.157820 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.157829 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa62132b0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6213a68] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa62131d8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa62131d8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6213a68] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.159092 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.159101 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6213fd0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6214788] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6213ef8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6213ef8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6214788] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.160396 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.160406 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6214cf0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa62154a8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6214c18] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6214c18] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa62154a8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.161665 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.161675 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6215a10] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa62161c8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6215938] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6215938] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa62161c8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.162927 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.162937 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6216730] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6216ee8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6216658] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6216658] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6216ee8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.164203 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.164214 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6217450] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6217c08] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6217378] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6217378] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6217c08] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.165463 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.165473 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6218170] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6218928] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6218098] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6218098] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6218928] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.166728 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.166738 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6218e90] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6219648] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6218db8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6218db8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6219648] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.169706 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.169717 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6219bb0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa621a368] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6219ad8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6219ad8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa621a368] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.170975 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.170985 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa621a8d0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa621b088] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa621a7f8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa621a7f8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa621b088] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.172254 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.172265 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa621b5f0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa621bda8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa621b518] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa621b518] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa621bda8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.173508 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.173517 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa621c310] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa621cac8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa621c238] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa621c238] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa621cac8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.174762 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.174772 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa621d030] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa621d7e8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa621cf58] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa621cf58] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa621d7e8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.176036 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.176047 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa621dd50] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa621e508] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa621dc78] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa621dc78] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa621e508] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.177296 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.177306 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa621ea70] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa621f228] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa621e998] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa621e998] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa621f228] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.178558 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.178567 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa621f790] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa621ff48] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa621f6b8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa621f6b8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa621ff48] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.179821 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.179831 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa62204b0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6220c68] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa62203d8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa62203d8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6220c68] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.181079 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.181089 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa62211d0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6221988] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa62210f8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa62210f8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6221988] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.182339 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.182348 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6221ef0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa62226a8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6221e18] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6221e18] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa62226a8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.183597 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.183607 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6222c10] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa62233c8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6222b38] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6222b38] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa62233c8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.184859 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.184869 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6223930] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa62240e8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6223858] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6223858] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa62240e8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.186109 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.186119 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6224650] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6224e08] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6224578] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6224578] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6224e08] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.187362 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.187371 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6225370] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6225b28] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6225298] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6225298] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6225b28] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.188637 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.188647 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6226090] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6226848] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6225fb8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6225fb8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6226848] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.189891 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.189901 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6226db0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6227568] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6226cd8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6226cd8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6227568] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.191148 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.191157 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6227ad0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6228288] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa62279f8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa62279f8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6228288] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.192411 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.192421 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa62287f0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6228fa8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6228718] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6228718] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6228fa8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.193669 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.193679 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6229510] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6229cc8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6229438] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6229438] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6229cc8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.194930 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.194940 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa622a230] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa622a9e8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa622a158] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa622a158] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa622a9e8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.196188 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.196198 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa622af50] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa622b708] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa622ae78] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa622ae78] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa622b708] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.197482 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.197492 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa622bc70] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa622c428] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa622bb98] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa622bb98] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa622c428] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.198745 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.198755 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa622c990] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa622d148] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa622c8b8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa622c8b8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa622d148] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.200016 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.200027 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa622d6b0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa622de68] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa622d5d8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa622d5d8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa622de68] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.201286 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.201295 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa622e3d0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa622eb88] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa622e2f8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa622e2f8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa622eb88] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.202542 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.202551 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa622f0f0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa622f8a8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa622f018] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa622f018] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa622f8a8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.203840 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.203851 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa622fe10] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa62305c8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa622fd38] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa622fd38] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa62305c8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.205101 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.205111 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6230b30] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa62312e8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6230a58] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6230a58] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa62312e8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.206360 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.206370 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6231850] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6232008] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6231778] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6231778] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6232008] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.207627 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.207637 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6232570] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6232d28] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6232498] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6232498] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6232d28] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.208888 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.208898 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6233290] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6233a48] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa62331b8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa62331b8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6233a48] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.210141 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.210151 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6233fb0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6234768] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6233ed8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6233ed8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6234768] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.211399 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.211409 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6234cd0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6235488] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6234bf8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6234bf8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6235488] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.212660 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.212670 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa62359f0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa62361a8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6235918] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6235918] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa62361a8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.213929 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.213938 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6236710] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6236ec8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6236638] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6236638] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6236ec8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.215180 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.215190 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6237430] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6237be8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6237358] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6237358] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6237be8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.216450 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.216460 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6238150] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6238908] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6238078] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6238078] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6238908] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.217705 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.217714 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6238e70] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6239628] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6238d98] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6238d98] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6239628] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.218960 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.218970 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6239b90] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa623a348] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6239ab8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6239ab8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa623a348] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.220234 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.220245 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa623a8b0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa623b068] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa623a7d8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa623a7d8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa623b068] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.221495 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.221504 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa623b5d0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa623bd88] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa623b4f8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa623b4f8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa623bd88] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.222754 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.222763 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa623c2f0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa623caa8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa623c218] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa623c218] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa623caa8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.224032 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.224042 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa623d010] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa623d7c8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa623cf38] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa623cf38] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa623d7c8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.225286 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.225296 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa623dd30] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa623e4e8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa623dc58] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa623dc58] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa623e4e8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.226547 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.226556 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa623ea50] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa623f208] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa623e978] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa623e978] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa623f208] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.227821 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.227832 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa623f770] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa623ff28] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa623f698] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa623f698] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa623ff28] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.229073 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.229083 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6240490] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6240c48] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa62403b8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa62403b8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6240c48] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.230326 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.230336 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa62411b0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6241968] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa62410d8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa62410d8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6241968] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.231578 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.231597 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6241ed0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6242688] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6241df8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6241df8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6242688] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.232844 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.232853 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6242bf0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63dff00ee8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6242b18] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6242b18] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63dff00ee8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.234106 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.234116 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa620e760] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63e3f00748] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa620e688] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa620e688] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63e3f00748] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.235349 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.235359 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63e3f00cb0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6244588] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63e3f00bd8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63e3f00bd8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6244588] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.236628 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.236638 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6244af0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa62452a8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6244a18] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6244a18] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa62452a8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.237894 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.237904 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6245810] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6245fc8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6245738] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6245738] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6245fc8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.239150 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.239159 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6246530] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6246ce8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6246458] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6246458] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6246ce8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.240425 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.240435 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6247250] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6247a08] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6247178] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6247178] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6247a08] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.241683 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.241692 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6247f70] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6248728] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6247e98] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6247e98] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6248728] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.242951 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.242961 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6248c90] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6249448] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6248bb8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6248bb8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6249448] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.244221 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.244231 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa62499b0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa624a168] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa62498d8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa62498d8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa624a168] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.245480 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.245489 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa624a6d0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa624ae88] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa624a5f8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa624a5f8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa624ae88] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.246739 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.246749 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa624b3f0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa624bba8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa624b318] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa624b318] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa624bba8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.248005 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.248015 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa624c110] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa624c8c8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa624c038] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa624c038] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa624c8c8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.249271 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.249281 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa624ce30] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa624d5e8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa624cd58] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa624cd58] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa624d5e8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.250527 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.250536 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa624db50] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa624e308] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa624da78] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa624da78] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa624e308] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.251791 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.251801 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa624e870] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa624f028] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa624e798] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa624e798] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa624f028] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.253060 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.253069 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa624f590] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa624fd48] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa624f4b8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa624f4b8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa624fd48] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.254313 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.254323 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa62502b0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6250a68] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa62501d8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa62501d8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6250a68] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.255568 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.255578 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6250fd0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6251788] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6250ef8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6250ef8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6251788] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.256864 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.256874 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6251cf0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa62524a8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6251c18] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6251c18] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa62524a8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.258123 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.258133 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6252a10] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa62531c8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6252938] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6252938] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa62531c8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.259376 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.259386 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6253730] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6253ee8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6253658] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6253658] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6253ee8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.260640 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.260650 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6254450] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6254c08] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6254378] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6254378] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6254c08] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.261896 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.261906 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6255170] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6255928] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6255098] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6255098] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6255928] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.263148 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.263158 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6255e90] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6256648] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6255db8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6255db8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6256648] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.264421 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.264431 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6256bb0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6257368] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6256ad8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6256ad8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6257368] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.265680 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.265689 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa62578d0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6258088] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa62577f8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa62577f8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6258088] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.266934 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.266944 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa62585f0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6258da8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6258518] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6258518] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6258da8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.268203 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.268212 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6259310] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6259ac8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6259238] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6259238] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6259ac8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.269462 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.269471 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa625a030] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa625a7e8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6259f58] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6259f58] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa625a7e8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.270721 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.270731 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa625ad50] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa625b508] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa625ac78] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa625ac78] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa625b508] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.271977 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.271987 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa625ba70] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa625c228] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa625b998] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa625b998] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa625c228] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.273232 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.273242 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa625c790] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa625cf48] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa625c6b8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa625c6b8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa625cf48] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.274487 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.274497 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa625d4b0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa625dc68] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa625d3d8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa625d3d8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa625dc68] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.275754 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.275764 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa625e1d0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa625e988] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa625e0f8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa625e0f8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa625e988] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.277048 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.277058 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa625eef0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa625f6a8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa625ee18] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa625ee18] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa625f6a8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.278317 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.278327 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa625fc10] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa62603c8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa625fb38] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa625fb38] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa62603c8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.279578 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.279602 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6260930] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa62610e8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6260858] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6260858] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa62610e8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.280863 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.280872 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6261650] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6261e08] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6261578] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6261578] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6261e08] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.282125 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.282134 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6262370] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6262b28] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6262298] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6262298] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6262b28] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.283397 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.283406 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6263090] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6263848] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6262fb8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6262fb8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6263848] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.284674 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.284684 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6263db0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6264568] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6263cd8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6263cd8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6264568] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.285933 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.285943 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6264ad0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6265288] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa62649f8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa62649f8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6265288] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.287192 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.287202 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa62657f0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6265fa8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6265718] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6265718] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6265fa8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.288455 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.288465 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6266510] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6266cc8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6266438] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6266438] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6266cc8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.289716 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.289726 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6267230] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa62679e8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6267158] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6267158] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa62679e8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.290967 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.290977 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6267f50] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6268708] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6267e78] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6267e78] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6268708] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.292230 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.292241 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6268c70] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa6269428] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6268b98] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6268b98] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6269428] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.293493 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.293502 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6269990] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa626a148] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa62698b8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa62698b8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa626a148] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.294750 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.294760 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa626a6b0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa626ae68] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa626a5d8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa626a5d8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa626ae68] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.297226 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.297237 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa626b3d0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa626bb88] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa626b2f8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa626b2f8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa626bb88] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.298480 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.298490 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa626c0f0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa626c8a8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa626c018] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa626c018] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa626c8a8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.299752 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.299762 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa626ce10] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa626d5c8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa626cd38] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa626cd38] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa626d5c8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.301022 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.301032 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa626db30] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa626e2e8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa626da58] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa626da58] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa626e2e8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.302285 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.302295 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa626e850] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63dbf00608] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa626e778] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa626e778] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63dbf00608] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.303538 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.303548 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63dbf00b70] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63d7f00798] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63dbf00a98] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63dbf00a98] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63d7f00798] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.304822 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.304832 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa626ee30] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63d7f00ed8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63d7f00c28] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63d7f00c28] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63d7f00ed8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.306073 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.306082 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa626f830] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f6aa626ffe8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa626f758] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa626f758] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa626ffe8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.307325 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.307335 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f6aa6270550] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd40df8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f6aa6270478] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f6aa6270478] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd40df8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.308584 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.308595 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd41360] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd41b18] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd41288] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd41288] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd41b18] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.309851 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.309861 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd42080] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd42838] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd41fa8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd41fa8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd42838] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.311098 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.311108 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd42da0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd43558] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd42cc8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd42cc8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd43558] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.312368 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.312377 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd43ac0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd44278] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd439e8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd439e8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd44278] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.313617 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.313627 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd447e0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd44f98] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd44708] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd44708] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd44f98] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.314888 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.314897 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd45500] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd45cb8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd45428] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd45428] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd45cb8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.316183 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.316193 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd46220] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd469d8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd46148] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd46148] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd469d8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.317456 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.317466 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd46f40] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd476f8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd46e68] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd46e68] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd476f8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.318723 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.318733 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd47c60] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd48418] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd47b88] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd47b88] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd48418] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.320006 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.320016 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd48980] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd49138] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd488a8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd488a8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd49138] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.321276 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.321285 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd496a0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd49e58] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd495c8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd495c8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd49e58] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.322543 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.322552 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd4a3c0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd4ab78] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd4a2e8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd4a2e8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd4ab78] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.323822 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.323832 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd4b0e0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd4b898] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd4b008] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd4b008] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd4b898] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.325098 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.325108 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd4be00] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd4c5b8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd4bd28] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd4bd28] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd4c5b8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.326370 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.326380 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd4cb20] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd4d2d8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd4ca48] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd4ca48] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd4d2d8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.327643 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.327653 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd4d840] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd4dff8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd4d768] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd4d768] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd4dff8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.328904 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.328914 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd4e560] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd4ed18] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd4e488] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd4e488] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd4ed18] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.330162 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.330172 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd4f280] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd4fa38] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd4f1a8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd4f1a8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd4fa38] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.331428 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.331437 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd4ffa0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd50758] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd4fec8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd4fec8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd50758] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.332764 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.332774 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd50cc0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd51478] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd50be8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd50be8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd51478] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.334024 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.334035 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd519e0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd52198] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd51908] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd51908] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd52198] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.335286 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.335295 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd52700] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd52eb8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd52628] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd52628] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd52eb8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.336556 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.336566 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd53420] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd53bd8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd53348] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd53348] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd53bd8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.337814 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.337823 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd54140] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd548f8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd54068] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd54068] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd548f8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.339076 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.339085 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd54e60] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd55618] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd54d88] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd54d88] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd55618] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.340344 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.340355 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd55b80] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd56338] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd55aa8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd55aa8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd56338] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.341606 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.341616 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd568a0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd57058] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd567c8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd567c8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd57058] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.342854 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.342864 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd575c0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd57d78] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd574e8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd574e8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd57d78] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.344131 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.344141 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd582e0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd58a98] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd58208] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd58208] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd58a98] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.345383 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.345393 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd59000] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd597b8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd58f28] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd58f28] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd597b8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.346643 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.346653 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd59d20] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd5a4d8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd59c48] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd59c48] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd5a4d8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.347975 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.347985 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd5aa40] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd5b1f8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd5a968] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd5a968] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd5b1f8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.349245 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.349254 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd5b760] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd5bf18] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd5b688] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd5b688] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd5bf18] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.350505 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.350515 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd5c480] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd5cc38] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd5c3a8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd5c3a8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd5cc38] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.351784 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.351794 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd5d1a0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd5d958] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd5d0c8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd5d0c8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd5d958] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.353073 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.353083 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd5dec0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd5e678] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd5dde8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd5dde8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd5e678] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.354348 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.354359 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd5ebe0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd5f398] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd5eb08] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd5eb08] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd5f398] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.355639 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.355650 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd5f900] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd600b8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd5f828] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd5f828] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd600b8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.356899 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.356909 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd60620] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd60dd8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd60548] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd60548] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd60dd8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.358183 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.358193 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd61340] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd61af8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd61268] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd61268] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd61af8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.359457 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.359467 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd62060] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd62818] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd61f88] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd61f88] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd62818] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.360730 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.360739 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd62d80] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd63538] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd62ca8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd62ca8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd63538] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.361991 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.362001 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd63aa0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd64258] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd639c8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd639c8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd64258] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.363246 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.363255 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd647c0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd64f78] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd646e8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd646e8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd64f78] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.364537 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.364548 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd654e0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd65c98] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd65408] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd65408] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd65c98] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.365769 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.365779 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd66200] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd669b8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd66128] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd66128] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd669b8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.367025 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.367035 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd66f20] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd676d8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd66e48] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd66e48] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd676d8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.368313 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.368325 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd67c40] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd683f8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd67b68] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd67b68] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd683f8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.369561 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.369570 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd68960] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd69118] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd68888] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd68888] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd69118] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.370809 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.370818 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd69680] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd69e38] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd695a8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd695a8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd69e38] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.372135 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.372147 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd6a3a0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd6ab58] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd6a2c8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd6a2c8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd6ab58] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.373396 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.373405 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd6b0c0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd6b878] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd6afe8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd6afe8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd6b878] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.374649 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.374658 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd6bde0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd6c598] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd6bd08] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd6bd08] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd6c598] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.375903 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.375913 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd6cb00] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd6d2b8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd6ca28] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd6ca28] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd6d2b8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.377159 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.377169 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd6d820] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd6dfd8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd6d748] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd6d748] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd6dfd8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.378414 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.378424 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd6e540] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd6ecf8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd6e468] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd6e468] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd6ecf8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.379693 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.379703 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd6f260] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd6fa18] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd6f188] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd6f188] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd6fa18] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.380945 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.380955 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd6ff80] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd70738] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd6fea8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd6fea8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd70738] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.382200 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.382210 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd70ca0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd71458] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd70bc8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd70bc8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd71458] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.383449 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.383459 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd719c0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd72178] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd718e8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd718e8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd72178] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.384729 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.384739 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd726e0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd72e98] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd72608] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd72608] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd72e98] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.385980 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.385990 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd73400] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd73bb8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd73328] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd73328] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd73bb8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.387421 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.387431 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd74120] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd748d8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd74048] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd74048] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd748d8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.388960 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.388970 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd74e40] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd755f8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd74d68] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd74d68] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd755f8] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.390245 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.390255 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd75b60] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd76318] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd75a88] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd75a88] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd76318] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.391497 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.391507 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd76880] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd77038] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd767a8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd767a8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd77038] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.392763 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.392773 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd775a0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd77d58] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd774c8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd774c8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd77d58] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.394017 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.394027 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd782c0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd78a78] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd781e8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd781e8] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd78a78] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.395284 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I0807 13:45:02.395293 28 infer_request.cc:900] "[request id: <id_unknown>] prepared: [0x0x7f63ebd78fe0] request id: , model: multilingual-e5-large-onnx, requested version: 1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f63ebd79798] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd78f08] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noverride inputs:\ninputs:\n[0x0x7f63ebd78f08] input: input_ids, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\n[0x0x7f63ebd79798] input: attention_mask, type: INT64, original shape: [1,512], batch + shape: [1,512], shape: [512]\noriginal requested outputs:\nrequested outputs:\nsentence_embedding\n"
I0807 13:45:02.395502 28 backend_model_instance.cc:772] "Starting backend thread for onnx_gpu_group_0 at nice 0 on device 0..."
I0807 13:45:02.395615 28 backend_model_instance.cc:606] "model 'multilingual-e5-large-onnx' instance onnx_gpu_group_0 is running warmup sample 'onnx_ort_warmup_min' for iteration 1"
I0807 13:45:02.395666 28 onnxruntime.cc:3049] "model multilingual-e5-large-onnx, instance onnx_gpu_group_0, executing 1 requests"
I0807 13:45:02.395690 28 onnxruntime.cc:1778] "TRITONBACKEND_ModelExecute: Running onnx_gpu_group_0 with 1 requests"
2024-08-07 13:45:02.398694467 [I:onnxruntime:log, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cuda. bin_num:0 (requested) num_bytes: 32 (actual) rounded_bytes:256
2024-08-07 13:45:02.398733873 [I:onnxruntime:log, bfc_arena.cc:206 Extend] Extended allocation by 1048576 bytes.
2024-08-07 13:45:02.398741563 [I:onnxruntime:log, bfc_arena.cc:209 Extend] Total allocated bytes: 1048576
2024-08-07 13:45:02.398747683 [I:onnxruntime:log, bfc_arena.cc:212 Extend] Allocated memory at 0x7f63f7e4ac00 to 0x7f63f7f4ac00
I0807 13:45:02.398865 28 onnxruntime.cc:1948] "Output Properties Unavailable. Using cpu as preferred location for output: sentence_embedding Error: [request id: <id_unknown>] Output properties are not available"
2024-08-07 13:45:38.091101153 [I:onnxruntime:log, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cpu. bin_num:4 (requested) num_bytes: 4096 (actual) rounded_bytes:4096
2024-08-07 13:45:38.091127681 [I:onnxruntime:log, bfc_arena.cc:206 Extend] Extended allocation by 1048576 bytes.
2024-08-07 13:45:38.091133379 [I:onnxruntime:log, bfc_arena.cc:209 Extend] Total allocated bytes: 1048576
2024-08-07 13:45:38.091138528 [I:onnxruntime:log, bfc_arena.cc:212 Extend] Allocated memory at 0x7f635800bc80 to 0x7f635810bc80
I0807 13:45:38.091247 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:45:38.091336 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:45:38.091356 28 backend_model_instance.cc:606] "model 'multilingual-e5-large-onnx' instance onnx_gpu_group_0 is running warmup sample 'onnx_ort_warmup_max' for iteration 1"
I0807 13:45:38.091612 28 onnxruntime.cc:3049] "model multilingual-e5-large-onnx, instance onnx_gpu_group_0, executing 256 requests"
I0807 13:45:38.091621 28 onnxruntime.cc:1778] "TRITONBACKEND_ModelExecute: Running onnx_gpu_group_0 with 256 requests"
I0807 13:45:38.091865 28 pinned_memory_manager.cc:198] "pinned memory allocation: size 1048576, addr 0x7f73ee000090"
I0807 13:45:38.093278 28 pinned_memory_manager.cc:198] "pinned memory allocation: size 1048576, addr 0x7f73ee1000a0"
I0807 13:45:38.093998 28 onnxruntime.cc:1948] "Output Properties Unavailable. Using cpu as preferred location for output: sentence_embedding Error: [request id: <id_unknown>] Output properties are not available"
2024-08-07 13:46:05.238053384 [W:onnxruntime:log, tensorrt_execution_provider.h:84 log] [2024-08-07 13:46:05 WARNING] UNSUPPORTED_STATE: Skipping tactic 0 due to insufficient memory on requested size of 15572403200 detected for tactic 0x0000000000000000.
2024-08-07 13:47:20.152082609 [I:onnxruntime:log, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cuda. bin_num:20 (requested) num_bytes: 536870912 (actual) rounded_bytes:536870912
2024-08-07 13:47:20.153010271 [I:onnxruntime:log, bfc_arena.cc:206 Extend] Extended allocation by 536870912 bytes.
2024-08-07 13:47:20.153019073 [I:onnxruntime:log, bfc_arena.cc:209 Extend] Total allocated bytes: 537919488
2024-08-07 13:47:20.153024011 [I:onnxruntime:log, bfc_arena.cc:212 Extend] Allocated memory at 0x7f6080000000 to 0x7f60a0000000
I0807 13:47:20.661772 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.661805 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.661817 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.661828 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.661839 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.661851 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.661859 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.661869 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.661879 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.661889 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.661899 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.661909 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.661918 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.661927 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.661935 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.661944 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.661954 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.661963 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.661972 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.661980 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.661990 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.661999 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662007 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662017 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662026 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662036 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662044 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662053 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662060 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662069 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662076 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662085 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662093 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662101 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662110 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662118 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662126 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662135 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662143 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662151 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662158 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662167 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662175 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662183 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662190 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662200 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662209 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662217 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662224 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662232 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662240 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662247 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662255 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662262 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662271 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662278 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662285 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662292 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662300 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662307 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662315 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662323 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662330 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662337 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662345 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662354 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662361 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662368 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662376 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662383 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662392 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662399 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662407 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662414 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662422 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662432 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662439 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662447 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662454 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662462 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662470 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662477 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662485 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662492 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662501 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662508 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662516 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662524 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662531 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662538 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662547 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662555 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662562 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662570 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662578 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662586 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662594 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662602 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662609 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662617 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662626 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662633 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662640 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662647 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662656 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662665 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662673 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662680 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662688 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662695 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662703 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662711 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662718 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662725 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662733 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662740 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662748 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662756 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662764 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662772 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662781 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662788 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662795 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662803 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662811 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662819 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662827 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662834 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662842 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662851 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662858 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662865 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662873 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662880 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662889 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662897 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662904 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662911 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662919 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662926 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662934 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662943 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662951 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662958 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662966 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662974 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662982 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662990 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.662997 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663005 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663014 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663022 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663029 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663036 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663044 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663051 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663059 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663066 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663074 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663081 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663089 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663097 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663105 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663112 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663119 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663127 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663136 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663144 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663151 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663158 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663166 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663175 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663183 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663191 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663200 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663208 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663216 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663223 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663231 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663238 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663246 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663254 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663263 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663272 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663280 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663288 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663297 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663304 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663313 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663321 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663330 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663340 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663349 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663356 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663365 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663375 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663384 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663392 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663400 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663408 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663416 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663426 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663435 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663443 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663450 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663460 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663468 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663476 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663486 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663494 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663502 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663511 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663522 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663530 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663539 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663546 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663555 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663563 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663573 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663588 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663597 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663605 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663615 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663624 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663635 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663644 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663652 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663661 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663670 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663680 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663689 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663698 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663705 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663714 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663724 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663732 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663741 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663748 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663758 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663767 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663776 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663784 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663793 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663800 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663809 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663818 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663828 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663836 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663844 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663852 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663861 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663870 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663879 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663887 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663894 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.663903 28 infer_response.cc:174] "add response output: output: sentence_embedding, type: FP32, shape: [1,1024]"
I0807 13:47:20.664366 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664378 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664387 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664397 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664406 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664415 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664423 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664433 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664443 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664451 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664459 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664468 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664476 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664485 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664493 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664502 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664510 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664520 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664528 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664536 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664544 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664553 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664561 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664569 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664578 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664587 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664595 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664603 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664611 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664619 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664627 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664636 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664644 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664652 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664660 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664669 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664677 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664685 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664694 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664702 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664710 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664718 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664726 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664734 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664742 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664750 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664758 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664766 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664774 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664782 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664791 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664799 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664807 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664815 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664823 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664831 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664839 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664847 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664855 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664863 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664871 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664879 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664888 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664896 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664904 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664913 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664921 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664929 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664937 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664945 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664953 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664961 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664969 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664977 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664985 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.664995 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665003 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665011 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665020 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665028 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665035 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665044 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665053 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665061 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665069 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665077 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665085 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665093 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665101 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665109 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665117 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665125 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665134 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665142 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665150 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665158 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665166 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665174 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665182 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665190 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665198 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665207 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665215 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665223 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665231 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665239 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665247 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665255 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665263 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665272 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665280 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665288 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665296 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665304 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665312 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665320 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665328 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665337 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665344 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665352 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665361 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665369 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665377 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665385 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665393 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665401 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665409 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665416 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665424 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665434 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665442 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665450 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665458 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665467 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665475 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665484 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665492 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665501 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665510 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665519 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665526 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665534 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665542 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665550 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665558 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665566 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665574 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665582 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665590 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665598 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665605 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665613 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665621 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665629 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665638 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665647 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665655 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665664 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665672 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665680 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665687 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665695 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665703 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665712 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665720 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665729 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665738 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665747 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665755 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665763 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665770 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665778 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665786 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665794 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665802 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665810 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665818 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665826 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665834 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665842 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665850 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665857 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665866 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665874 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665882 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665890 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665899 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665908 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665916 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665924 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665932 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665940 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665948 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665956 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665965 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665974 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665982 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665990 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.665999 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666007 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666015 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666023 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666031 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666039 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666047 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666055 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666063 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666071 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666079 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666087 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666095 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666103 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666111 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666119 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666127 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666135 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666143 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666152 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666160 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666168 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666176 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666185 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666192 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666201 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666209 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666217 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666224 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666233 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666241 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666248 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666256 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666264 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666272 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666281 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666289 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666296 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666304 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666312 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666320 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666328 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666337 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666346 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666354 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666362 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666370 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666379 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666387 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666396 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666404 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666412 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666420 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666428 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666436 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666445 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666453 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666462 28 infer_request.cc:131] "[request id: <id_unknown>] Setting state from INITIALIZED to RELEASED"
I0807 13:47:20.666483 28 pinned_memory_manager.cc:226] "pinned memory deallocation: addr 0x7f73ee000090"
I0807 13:47:20.666493 28 pinned_memory_manager.cc:226] "pinned memory deallocation: addr 0x7f73ee1000a0"
I0807 13:47:20.696928 28 model_lifecycle.cc:838] "successfully loaded 'multilingual-e5-large-onnx'"
I0807 13:47:20.696927 28 dynamic_batch_scheduler.cc:303] "Starting dynamic-batcher thread for multilingual-e5-large-onnx at nice 0..."
I0807 13:47:20.697481 28 api.cc:382] "Using credential    for path  s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd/wb_embedder_v0"
I0807 13:47:20.996036 28 model_lifecycle.cc:472] "loading: wb_embedder_v0:1"
I0807 13:47:20.996497 28 ensemble_model.cc:57] "ensemble model for wb_embedder_v0\n"
I0807 13:47:20.996558 28 model_lifecycle.cc:838] "successfully loaded 'wb_embedder_v0'"
I0807 13:47:20.996658 28 server.cc:606]
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0807 13:47:20.996735 28 server.cc:633]
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","backend-directory":"/opt/tritonserver/backends","min-compute-capability":"6.000000","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","backend-directory":"/opt/tritonserver/backends","min-compute-capability":"6.000000","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0807 13:47:20.996858 28 server.cc:676]
+--------------------------------------+---------+--------+
| Model                                | Version | Status |
+--------------------------------------+---------+--------+
| multilingual-e5-large-onnx           | 1       | READY  |
| multilingual-e5-large-postprocessing | 1       | READY  |
| multilingual-e5-large-preprocessing  | 1       | READY  |
| wb_embedder_v0                       | 1       | READY  |
+--------------------------------------+---------+--------+

I0807 13:47:21.037703 28 metrics.cc:877] "Collecting metrics for GPU 0: NVIDIA A800 80GB PCIe"
I0807 13:47:21.044531 28 metrics.cc:770] "Collecting CPU metrics"
I0807 13:47:21.044814 28 tritonserver.cc:2557]
+----------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                           |
+----------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                                          |
| server_version                   | 2.46.0                                                                                                                                                                                                          |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data parameters statistics trace logging |
| model_repository_path[0]         | s3://https://s3-xc1.wb.ru:443/triton-multilingual-e5-large/models/prd                                                                                                                                           |
| model_control_mode               | MODE_NONE                                                                                                                                                                                                       |
| strict_model_config              | 0                                                                                                                                                                                                               |
| model_config_name                |                                                                                                                                                                                                                 |
| rate_limit                       | OFF                                                                                                                                                                                                             |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                                       |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                                        |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                             |
| strict_readiness                 | 1                                                                                                                                                                                                               |
| exit_timeout                     | 30                                                                                                                                                                                                              |
| cache_enabled                    | 0                                                                                                                                                                                                               |
+----------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0807 13:47:21.046671 28 grpc_server.cc:2370]
+----------------------------------------------+---------+
| GRPC KeepAlive Option                        | Value   |
+----------------------------------------------+---------+
| keepalive_time_ms                            | 7200000 |
| keepalive_timeout_ms                         | 20000   |
| keepalive_permit_without_calls               | 0       |
| http2_max_pings_without_data                 | 2       |
| http2_min_recv_ping_interval_without_data_ms | 300000  |
| http2_max_ping_strikes                       | 2       |
+----------------------------------------------+---------+

I0807 13:47:21.047772 28 grpc_server.cc:102] "Ready for RPC 'Check', 0"
I0807 13:47:21.047837 28 grpc_server.cc:102] "Ready for RPC 'ServerLive', 0"
I0807 13:47:21.047864 28 grpc_server.cc:102] "Ready for RPC 'ServerReady', 0"
I0807 13:47:21.047896 28 grpc_server.cc:102] "Ready for RPC 'ModelReady', 0"
I0807 13:47:21.047922 28 grpc_server.cc:102] "Ready for RPC 'ServerMetadata', 0"
I0807 13:47:21.047949 28 grpc_server.cc:102] "Ready for RPC 'ModelMetadata', 0"
I0807 13:47:21.047972 28 grpc_server.cc:102] "Ready for RPC 'ModelConfig', 0"
I0807 13:47:21.048003 28 grpc_server.cc:102] "Ready for RPC 'SystemSharedMemoryStatus', 0"
I0807 13:47:21.048031 28 grpc_server.cc:102] "Ready for RPC 'SystemSharedMemoryRegister', 0"
I0807 13:47:21.048057 28 grpc_server.cc:102] "Ready for RPC 'SystemSharedMemoryUnregister', 0"
I0807 13:47:21.048082 28 grpc_server.cc:102] "Ready for RPC 'CudaSharedMemoryStatus', 0"
I0807 13:47:21.048108 28 grpc_server.cc:102] "Ready for RPC 'CudaSharedMemoryRegister', 0"
I0807 13:47:21.048135 28 grpc_server.cc:102] "Ready for RPC 'CudaSharedMemoryUnregister', 0"
I0807 13:47:21.048160 28 grpc_server.cc:102] "Ready for RPC 'RepositoryIndex', 0"
I0807 13:47:21.048184 28 grpc_server.cc:102] "Ready for RPC 'RepositoryModelLoad', 0"
I0807 13:47:21.048210 28 grpc_server.cc:102] "Ready for RPC 'RepositoryModelUnload', 0"
I0807 13:47:21.048235 28 grpc_server.cc:102] "Ready for RPC 'ModelStatistics', 0"
I0807 13:47:21.048258 28 grpc_server.cc:102] "Ready for RPC 'Trace', 0"
I0807 13:47:21.048283 28 grpc_server.cc:102] "Ready for RPC 'Logging', 0"
I0807 13:47:21.048326 28 grpc_server.cc:366] "Thread started for CommonHandler"
I0807 13:47:21.049126 28 infer_handler.cc:680] "New request handler for ModelInferHandler, 0"
I0807 13:47:21.049199 28 infer_handler.h:1322] "Thread started for ModelInferHandler"
I0807 13:47:21.049401 28 infer_handler.cc:680] "New request handler for ModelInferHandler, 0"
I0807 13:47:21.049474 28 infer_handler.h:1322] "Thread started for ModelInferHandler"
I0807 13:47:21.049686 28 stream_infer_handler.cc:128] "New request handler for ModelStreamInferHandler, 0"
I0807 13:47:21.049756 28 infer_handler.h:1322] "Thread started for ModelStreamInferHandler"
I0807 13:47:21.049779 28 grpc_server.cc:2463] "Started GRPCInferenceService at 0.0.0.0:8001"
I0807 13:47:21.050369 28 http_server.cc:4692] "Started HTTPService at 0.0.0.0:8000"
I0807 13:47:21.094767 28 http_server.cc:362] "Started Metrics Service at 0.0.0.0:8002"
I0807 13:47:29.939566 28 http_server.cc:317] "HTTP request: 0 /metrics"